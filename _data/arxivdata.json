{"0704.2241":{"title":"Why should anyone care about computing with anyons?","abstract":"In this article we present a pedagogical introduction of the main ideas and recent advances in the area of topological quantum computation. We give an overview of the concept of anyons and their exotic statistics, present various models that exhibit topological behavior, and we establish their relation to quantum computation. Possible directions for the physical realization of topological systems and the detection of anyonic behavior are elaborated.","authors":"Gavin K. Brennen, Jiannis K. Pachos"},"0708.1879":{"title":"Quantum random access memory","abstract":"A random access memory (RAM) uses n bits to randomly address N=2^n distinct memory cells. A quantum random access memory (qRAM) uses n qubits to address any quantum superposition of N memory cells. We present an architecture that exponentially reduces the requirements for a memory call: O(log N) switches need be thrown instead of the N used in conventional (classical or quantum) RAM designs. This yields a more robust qRAM algorithm, as it in general requires entanglement among exponentially less gates, and leads to an exponential decrease in the power needed for addressing. A quantum optical implementation is presented.","authors":"Vittorio Giovannetti, Seth Lloyd, Lorenzo Maccone"},"0906.4716":{"title":"Algebraic characterization of X-states in quantum information","abstract":"A class of two-qubit states called X-states are increasingly being used to discuss entanglement and other quantum correlations in the field of quantum information. Maximally entangled Bell states and \"Werner\" states are subsets of them. Apart from being so named because their density matrix looks like the letter X, there is not as yet any characterization of them. The su(2) X su(2) X u(1) subalgebra of the full su(4) algebra of two qubits is pointed out as the underlying invariance of this class of states. X-states are a seven-parameter family associated with this subalgebra of seven operators. This recognition provides a route to preparing such states and also a convenient algebraic procedure for analytically calculating their properties. At the same time, it points to other groups of seven-parameter states that, while not at first sight appearing similar, are also invariant under the same subalgebra. And it opens the way to analyzing invariant states of other subalgebras in bipartite systems.","authors":"A. R. P. Rau"},"1108.1791":{"title":"Why Philosophers Should Care About Computational Complexity","abstract":"One might think that, once we know something is computable, how efficiently it can be computed is a practical question with little further philosophical importance. In this essay, I offer a detailed case that one would be wrong. In particular, I argue that computational complexity theory---the field that studies the resources (such as time, space, and randomness) needed to solve computational problems---leads to new perspectives on the nature of mathematical knowledge, the strong AI debate, computationalism, the problem of logical omniscience, Hume's problem of induction, Goodman's grue riddle, the foundations of quantum mechanics, economic rationality, closed timelike curves, and several other topics of philosophical interest. I end by discussing aspects of complexity theory itself that could benefit from philosophical analysis.","authors":"Scott Aaronson"},"1305.3977":{"title":"Invariant Gaussian processes and independent sets on regular graphs of large girth","abstract":"We prove that every 3-regular, n-vertex simple graph with sufficiently large girth contains an independent set of size at least 0.4361n. (The best known bound is 0.4352n.) In fact, computer simulation suggests that the bound our method provides is about 0.438n. Our method uses invariant Gaussian processes on the d-regular tree that satisfy the eigenvector equation at each vertex for a certain eigenvalue \\lambda. We show that such processes can be approximated by i.i.d. factors provided that $|\\lambda| \\leq 2\\sqrt{d-1}$. We then use these approximations for $\\lambda = -2\\sqrt{d-1}$ to produce factor of i.i.d. independent sets on regular trees.","authors":"Endre Csóka, Balázs Gerencsér, Viktor Harangi, Bálint Virág"},"1308.0266":{"title":"Local algorithms, regular graphs of large girth, and random regular graphs","abstract":"We introduce a general class of algorithms and supply a number of general results useful for analysing these algorithms when applied to regular graphs of large girth. As a result, we can transfer a number of results proved for random regular graphs into (deterministic) results about all regular graphs with sufficiently large girth. This is an uncommon direction of transfer of results, which is usually from the deterministic setting to the random one. In particular, this approach enables, for the first time, the achievement of results equivalent to those obtained on random regular graphs by a powerful class of algorithms which contain prioritised actions. As examples, we obtain new upper or lower bounds on the size of maximum independent sets, minimum dominating sets, maximum and minimum bisection, maximum $k$-independent sets, minimum $k$-dominating sets and minimum connected and weakly-connected dominating sets in $r$-regular graphs with large girth.","authors":"Carlos Hoppen, Nicholas Wormald"},"1401.4197":{"title":"Factors of IID on Trees","abstract":"Classical ergodic theory for integer-group actions uses entropy as a complete invariant for isomorphism of IID (independent, identically distributed) processes (a.k.a. product measures). This theory holds for amenable groups as well. Despite recent spectacular progress of Bowen, the situation for non-amenable groups, including free groups, is still largely mysterious. We present some illustrative results and open questions on free groups, which are particularly interesting in combinatorics, statistical physics, and probability. Our results include bounds on minimum and maximum bisection for random cubic graphs that improve on all past bounds.","authors":"Russell Lyons"},"1408.5593":{"title":"Event-by-event simulation of a quantum delayed-choice experiment","abstract":"The quantum delayed-choice experiment of Tang et al. [Nature Photonics 6 (2012) 600] is simulated on the level of individual events without making reference to concepts of quantum theory or without solving a wave equation. The simulation results are in excellent agreement with the quantum theoretical predictions of this experiment. The implication of the work presented in the present paper is that the experiment of Tang et al. can be explained in terms of cause-and-effect processes in an event-by-event manner.","authors":"Hylke C. Donker, Hans De Raedt, Kristel Michielsen"},"1412.8427":{"title":"Boson Sampling for Molecular Vibronic Spectra","abstract":"Quantum computers are expected to be more efficient in performing certain computations than any classical machine. Unfortunately, the technological challenges associated with building a full-scale quantum computer have not yet allowed the experimental verification of such an expectation. Recently, boson sampling has emerged as a problem that is suspected to be intractable on any classical computer, but efficiently implementable with a linear quantum optical setup. Therefore, boson sampling may offer an experimentally realizable challenge to the Extended Church-Turing thesis and this remarkable possibility motivated much of the interest around boson sampling, at least in relation to complexity-theoretic questions. In this work, we show that the successful development of a boson sampling apparatus would not only answer such inquiries, but also yield a practical tool for difficult molecular computations. Specifically, we show that a boson sampling device with a modified input state can be used to generate molecular vibronic spectra, including complicated effects such as Duschinsky rotations.","authors":"Joonsuk Huh, Gian Giacomo Guerreschi, Borja Peropadre, Jarrod R. McClean, Alán Aspuru-Guzik"},"1502.04398":{"title":"A Dynamic Programming Approach to the Parisi Functional","abstract":"G.Parisi predicted an important variational formula for the thermodynamic limit of the intensive free energy for a class of mean field spin glasses. In this paper, we present an elementary approach to the study of the Parisi functional using stochastic dynamic programing and semi-linear PDE. We give a derivation of important properties of the Parisi PDE avoiding the use of Ruelle Probability Cascades and Cole-Hopf transformations. As an application, we give a simple proof of the strict convexity of the Parisi functional, which was recently proved by Auffinger and Chen in [2].","authors":"Aukosh Jagannath, Ian Tobasco"},"1503.03923":{"title":"Extremal Cuts of Sparse Random Graphs","abstract":"For Erd\\H{o}s-R\\'enyi random graphs with average degree $\\gamma$, and uniformly random $\\gamma$-regular graph on $n$ vertices, we prove that with high probability the size of both the Max-Cut and maximum bisection are $n\\Big(\\frac{\\gamma}{4} + {{\\sf P}}_* \\sqrt{\\frac{\\gamma}{4}} + o(\\sqrt{\\gamma})\\Big) + o(n)$ while the size of the minimum bisection is $n\\Big(\\frac{\\gamma}{4}-{{\\sf P}}_*\\sqrt{\\frac{\\gamma}{4}} + o(\\sqrt{\\gamma})\\Big) + o(n)$. Our derivation relates the free energy of the anti-ferromagnetic Ising model on such graphs to that of the Sherrington-Kirkpatrick model, with ${{\\sf P}}_* \\approx 0.7632$ standing for the ground state energy of the latter, expressed analytically via Parisi's formula.","authors":"Amir Dembo, Andrea Montanari, Subhabrata Sen"},"1509.08435":{"title":"Efficient long distance quantum communication","abstract":"Despite the tremendous progress of quantum cryptography, efficient quantum communication over long distances (&gt;1000km) remains an outstanding challenge due to fiber attenuation and operation errors accumulated over the entire communication distance. Quantum repeaters, as a promising approach, can overcome both photon loss and operation errors, and hence significantly speedup the communication rate. Depending on the methods used to correct loss and operation errors, all the proposed QR schemes can be classified into three categories (generations). Here we present the first systematic comparison of three generations of quantum repeaters by evaluating the cost of both temporal and physical resources, and identify the optimized quantum repeater architecture for a given set of experimental parameters. Our work provides a roadmap for the experimental realizations of highly efficient quantum networks over transcontinental distances.","authors":"Sreraman Muralidharan, Linshu Li, Jungsang Kim, Norbert Lütkenhaus, Mikhail D. Lukin, Liang Jiang"},"1602.07674":{"title":"Quantum Supremacy through the Quantum Approximate Optimization Algorithm","abstract":"The Quantum Approximate Optimization Algorithm (QAOA) is designed to run on a gate model quantum computer and has shallow depth. It takes as input a combinatorial optimization problem and outputs a string that satisfies a high fraction of the maximum number of clauses that can be satisfied. For certain problems the lowest depth version of the QAOA has provable performance guarantees although there exist classical algorithms that have better guarantees. Here we argue that beyond its possible computational value the QAOA can exhibit a form of Quantum Supremacy in that, based on reasonable complexity theoretic assumptions, the output distribution of even the lowest depth version cannot be efficiently simulated on any classical device. We contrast this with the case of sampling from the output of a quantum computer running the Quantum Adiabatic Algorithm (QADI) with the restriction that the Hamiltonian that governs the evolution is gapped and stoquastic. Here we show that there is an oracle that would allow sampling from the QADI but even with this oracle, if one could efficiently classically sample from the output of the QAOA, the Polynomial Hierarchy would collapse. This suggests that the QAOA is an excellent candidate to run on near term quantum computers not only because it may be of use for optimization but also because of its potential as a route to establishing quantum supremacy.","authors":"Edward Farhi, Aram W Harrow"},"1604.01384":{"title":"A Complete Characterization of Unitary Quantum Space","abstract":"Motivated by understanding the power of quantum computation with restricted number of qubits, we give two complete characterizations of unitary quantum space bounded computation. First we show that approximating an element of the inverse of a well-conditioned efficiently encoded $2^{k(n)}\\times 2^{k(n)}$ matrix is complete for the class of problems solvable by quantum circuits acting on $\\mathcal{O}(k(n))$ qubits with all measurements at the end of the computation. Similarly, estimating the minimum eigenvalue of an efficiently encoded Hermitian $2^{k(n)}\\times 2^{k(n)}$ matrix is also complete for this class. In the logspace case, our results improve on previous results of Ta-Shma [STOC '13] by giving new space-efficient quantum algorithms that avoid intermediate measurements, as well as showing matching hardness results. Additionally, as a consequence we show that PreciseQMA, the version of QMA with exponentially small completeness-soundess gap, is equal to PSPACE. Thus, the problem of estimating the minimum eigenvalue of a local Hamiltonian to inverse exponential precision is PSPACE-complete, which we show holds even in the frustration-free case. Finally, we can use this characterization to give a provable setting in which the ability to prepare the ground state of a local Hamiltonian is more powerful than the ability to prepare PEPS states. Interestingly, by suitably changing the parameterization of either of these problems we can completely characterize the power of quantum computation with simultaneously bounded time and space.","authors":"Bill Fefferman, Cedric Yen-Yu Lin"},"1707.03429":{"title":"Open Quantum Assembly Language","abstract":"This document describes a quantum assembly language (QASM) called OpenQASM that is used to implement experiments with low depth quantum circuits. OpenQASM represents universal physical circuits over the CNOT plus SU(2) basis with straight-line code that includes measurement, reset, fast feedback, and gate subroutines. The simple text language can be written by hand or by higher level tools and may be executed on the IBM Q Experience.","authors":"Andrew W. Cross, Lev S. Bishop, John A. Smolin, Jay M. Gambetta"},"1707.05386":{"title":"Suboptimality of local algorithms for a class of max-cut problems","abstract":"We show that in random $K$-uniform hypergraphs of constant average degree, for even $K \\geq 4$, local algorithms defined as factors of i.i.d. can not find nearly maximal cuts, when the average degree is sufficiently large. These algorithms have been used frequently to obtain lower bounds for the max-cut problem on random graphs, but it was not known whether they could be successful in finding nearly maximal cuts. This result follows from the fact that the overlap of any two nearly maximal cuts in such hypergraphs does not take values in a certain non-trivial interval - a phenomenon referred to as the overlap gap property - which is proved by comparing diluted models with large average degree with appropriate fully connected spin glass models and showing the overlap gap property in the latter setting.","authors":"Wei-Kuo Chen, David Gamarnik, Dmitry Panchenko, Mustazee Rahman"},"1802.07744":{"title":"Contextuality bounds the efficiency of classical simulation of quantum processes","abstract":"Contextuality has been conjectured to be a super-classical resource for quantum computation, analogous to the role of non-locality as a super-classical resource for communication. We show that the presence of contextuality places a lower bound on the amount of classical memory required to simulate any quantum sub-theory, thereby establishing a quantitative connection between contextuality and classical simulability. We apply our result to the qubit stabilizer sub-theory, where the presence of state-independent contextuality has been an obstacle in establishing contextuality as a quantum computational resource. We find that the presence of contextuality in this sub-theory demands that the minimum number of classical bits of memory required to simulate a multi-qubit system must scale quadratically in the number of qubits; notably, this is the same scaling as the Gottesman-Knill algorithm. We contrast this result with the (non-contextual) qudit case, where linear scaling is possible.","authors":"Angela Karanjai, Joel J. Wallman, Stephen D. Bartlett"},"1803.02176":{"title":"Quantum Walks via Quantum Cellular Automata","abstract":"Very much as its classical counterpart, quantum cellular automata are expected to be a great tool for simulating complex quantum systems. Here we introduce a partitioned model of quantum cellular automata and show how it can simulate, with the same amount of resources (in terms of effective Hilbert space dimension), various models of quantum walks. All the algorithms developed within quantum walk models are thus directly inherited by the quantum cellular automata. The latter, however, has its structure based on local interactions between qubits, and as such it can be more suitable for present (and future) experimental implementations.","authors":"Pedro C. S. Costa, Renato Portugal, Fernando de Melo"},"1804.09130":{"title":"On the representation of Boolean and real functions as Hamiltonians for quantum computing","abstract":"Mapping functions on bits to Hamiltonians acting on qubits has many applications in quantum computing. In particular, Hamiltonians representing Boolean functions are required for applications of quantum annealing or the quantum approximate optimization algorithm to combinatorial optimization problems. We show how such functions are naturally represented by Hamiltonians given as sums of Pauli $Z$ operators (Ising spin operators) with the terms of the sum corresponding to the function's Fourier expansion. For many classes of functions which are given by a compact description, such as a Boolean formula in conjunctive normal form that gives an instance of the satisfiability problem, it is #P-hard to compute its Hamiltonian representation. On the other hand, no such difficulty exists generally for constructing Hamiltonians representing a real function such as a sum of local Boolean clauses. We give composition rules for explicitly constructing Hamiltonians representing a wide variety of Boolean and real functions by combining Hamiltonians representing simpler clauses as building blocks. We apply our results to the construction of controlled-unitary operators, and to the special case of operators that compute function values in an ancilla qubit register. Finally, we outline several additional applications and extensions of our results. A primary goal of this paper is to provide a $\\textit{design toolkit for quantum optimization}$ which may be utilized by experts and practitioners alike in the construction and analysis of new quantum algorithms, and at the same time to demystify the various constructions appearing in the literature.","authors":"Stuart Hadfield"},"1805.03265":{"title":"Quantum Algorithms for Scientific Computing and Approximate Optimization","abstract":"Quantum computation appears to offer significant advantages over classical computation and this has generated a tremendous interest in the field. In this thesis we consider the application of quantum computers to scientific computing and combinatorial optimization. We study five problems. The first three deal with quantum algorithms for computational problems in science and engineering, including quantum simulation of physical systems. In particular, we study quantum algorithms for numerical computation, for the approximation of ground and excited state energies of the Schr\\\"odinger equation, and for Hamiltonian simulation with applications to physics and chemistry. The remaining two deal with quantum algorithms for approximate optimization. We study the performance of the quantum approximate optimization algorithm (QAOA), and show a generalization of QAOA, the $\\textit{quantum}$ $\\textit{alternating}$ $\\textit{operator}$ $\\textit{ansatz}$, particularly suitable for constrained optimization problems and low-resource implementations on near-term quantum devices.","authors":"Stuart Hadfield"},"1806.01838":{"title":"Quantum singular value transformation and beyond: exponential improvements for quantum matrix arithmetics","abstract":"Quantum computing is powerful because unitary operators describing the time-evolution of a quantum system have exponential size in terms of the number of qubits present in the system. We develop a new \"Singular value transformation\" algorithm capable of harnessing this exponential advantage, that can apply polynomial transformations to the singular values of a block of a unitary, generalizing the optimal Hamiltonian simulation results of Low and Chuang. The proposed quantum circuits have a very simple structure, often give rise to optimal algorithms and have appealing constant factors, while usually only use a constant number of ancilla qubits. We show that singular value transformation leads to novel algorithms. We give an efficient solution to a certain \"non-commutative\" measurement problem and propose a new method for singular value estimation. We also show how to exponentially improve the complexity of implementing fractional queries to unitaries with a gapped spectrum. Finally, as a quantum machine learning application we show how to efficiently implement principal component regression. \"Singular value transformation\" is conceptually simple and efficient, and leads to a unified framework of quantum algorithms incorporating a variety of quantum speed-ups. We illustrate this by showing how it generalizes a number of prominent quantum algorithms, including: optimal Hamiltonian simulation, implementing the Moore-Penrose pseudoinverse with exponential precision, fixed-point amplitude amplification, robust oblivious amplitude amplification, fast QMA amplification, fast quantum OR lemma, certain quantum walk results and several quantum machine learning algorithms. In order to exploit the strengths of the presented method it is useful to know its limitations too, therefore we also prove a lower bound on the efficiency of singular value transformation, which often gives optimal bounds.","authors":"András Gilyén, Yuan Su, Guang Hao Low, Nathan Wiebe"},"1810.07690":{"title":"Forecasting financial crashes with quantum computing","abstract":"A key problem in financial mathematics is the forecasting of financial crashes: if we perturb asset prices, will financial institutions fail on a massive scale? This was recently shown to be a computationally intractable (NP-hard) problem. Financial crashes are inherently difficult to predict, even for a regulator which has complete information about the financial system. In this paper we show how this problem can be handled by quantum annealers. More specifically, we map the equilibrium condition of a toy-model financial network to the ground-state problem of a spin-1/2 quantum Hamiltonian with 2-body interactions, i.e., a quadratic unconstrained binary optimization (QUBO) problem. The equilibrium market values of institutions after a sudden shock to the network can then be calculated via adiabatic quantum computation and, more generically, by quantum annealers. Our procedure could be implemented on near-term quantum processors, thus providing a potentially more efficient way to assess financial equilibrium and predict financial crashes.","authors":"Roman Orus, Samuel Mugel, Enrique Lizaso"},"1811.06657":{"title":"Time crystals in periodically driven systems","abstract":"When the discrete time-translation symmetry of isolated, periodically driven systems is spontaneously broken, a new phase of matter can emerge. We review some recent developments on both the theoretical underpinnings and experimental realizations of time crystalline order. Particular attention is placed on delineating the key features of time crystals, which distinguish them from other oscillatory non-equilibrium phenomena.","authors":"Norman Y. Yao, Chetan Nayak"},"1811.08017":{"title":"A random compiler for fast Hamiltonian simulation","abstract":"The dynamics of a quantum system can be simulated using a quantum computer by breaking down the unitary into a quantum circuit of one and two qubit gates. The most established methods are the Trotter-Suzuki decompositions, for which rigorous bounds on the circuit size depend on the number of terms $L$ in the system Hamiltonian and the size of the largest term in the Hamiltonian $\\Lambda$. Consequently, Trotter-Suzuki is only practical for sparse Hamiltonians. Trotter-Suzuki is a deterministic compiler but it was recently shown that randomised compiling offers lower overheads. Here we present and analyse a randomised compiler for Hamiltonian simulation where gate probabilities are proportional to the strength of a corresponding term in the Hamiltonian. This approach requires a circuit size independent of $L$ and $\\Lambda$, but instead depending on $\\lambda$ the absolute sum of Hamiltonian strengths (the $\\ell_1$ norm). Therefore, it is especially suited to electronic structure Hamiltonians relevant to quantum chemistry. Considering propane, carbon dioxide and ethane, we observe speed-ups compared to standard Trotter-Suzuki of between $306\\times$ and $1591\\times$ for physically significant simulation times at precision $10^{-3}$. Performing phase estimation at chemical accuracy, we report that the savings are similar.","authors":"Earl Campbell"},"1904.01502":{"title":"Quantum advantage with noisy shallow circuits in 3D","abstract":"Prior work has shown that there exists a relation problem which can be solved with certainty by a constant-depth quantum circuit composed of geometrically local gates in two dimensions, but cannot be solved with high probability by any classical constant depth circuit composed of bounded fan-in gates. Here we provide two extensions of this result. Firstly, we show that a separation in computational power persists even when the constant-depth quantum circuit is restricted to geometrically local gates in one dimension. The corresponding quantum algorithm is the simplest we know of which achieves a quantum advantage of this type. It may also be more practical for future implementations. Our second, main result, is that a separation persists even if the shallow quantum circuit is corrupted by noise. We construct a relation problem which can be solved with near certainty using a noisy constant-depth quantum circuit composed of geometrically local gates in three dimensions, provided the noise rate is below a certain constant threshold value. On the other hand, the problem cannot be solved with high probability by a noise-free classical circuit of constant depth. A key component of the proof is a quantum error-correcting code which admits constant-depth logical Clifford gates and single-shot logical state preparation. We show that the surface code meets these criteria. To this end, we provide a protocol for single-shot logical state preparation in the surface code which may be of independent interest.","authors":"Sergey Bravyi, David Gosset, Robert Koenig, Marco Tomamichel"},"1904.02260":{"title":"Contextuality Test of the Nonclassicality of Variational Quantum Eigensolvers","abstract":"Contextuality is an indicator of non-classicality, and a resource for various quantum procedures. In this paper, we use contextuality to evaluate the variational quantum eigensolver (VQE), one of the most promising tools for near-term quantum simulation. We present an efficiently computable test to determine whether or not the objective function for a VQE procedure is contextual. We apply this test to evaluate the contextuality of experimental implementations of VQE, and determine that several, but not all, fail this test of quantumness.","authors":"William M. Kirby, Peter J. Love"},"1906.02700":{"title":"Quantum Approximate Optimization of the Long-Range Ising Model with a Trapped-Ion Quantum Simulator","abstract":"Quantum computers and simulators may offer significant advantages over their classical counterparts, providing insights into quantum many-body systems and possibly improving performance for solving exponentially hard problems, such as optimization and satisfiability. Here we report the implementation of a low-depth Quantum Approximate Optimization Algorithm (QAOA) using an analog quantum simulator. We estimate the ground state energy of the Transverse Field Ising Model with long-range interactions with tunable range and we optimize the corresponding combinatorial classical problem by sampling the QAOA output with high-fidelity, single-shot individual qubit measurements. We execute the algorithm with both an exhaustive search and closed-loop optimization of the variational parameters, approximating the ground state energy with up to 40 trapped-ion qubits. We benchmark the experiment with bootstrapping heuristic methods scaling polynomially with the system size. We observe, in agreement with numerics, that the QAOA performance does not degrade significantly as we scale up the system size, and that the runtime is approximately independent from the number of qubits. We finally give a comprehensive analysis of the errors occurring in our system, a crucial step in the path forward towards the application of the QAOA to more general problem instances.","authors":"G. Pagano, A. Bapat, P. Becker, K. S. Collins, A. De, P. W. Hess, H. B. Kaplan, A. Kyprianidis, W. L. Tan, C. Baldwin, L. T. Brady, A. Deshpande, F. Liu, S. Jordan, A. V. Gorshkov, C. Monroe"},"1906.08948":{"title":"Quantum Annealing: a journey through Digitalization, Control, and hybrid Quantum Variational schemes","abstract":"We establish and discuss a number of connections between a digitized version of Quantum Annealing (QA) with the Quantum Approximate Optimization Algorithm (QAOA) introduced by Farhi et al. (arXiv:1411.4028) as an alternative hybrid quantum-classical variational scheme for quantum-state preparation and optimization. We introduce a technique that allows to prove, for instance, a rigorous bound concerning the performance of QAOA for MaxCut on a $2$-regular graph, equivalent to an unfrustrated antiferromagnetic Ising chain. The bound shows that the optimal variational error of a depth-$\\mathrm{P}$ quantum circuit has to satisfy $\\epsilon^\\mathrm{res}_{\\mathrm{P}}\\ge (2\\mathrm{P}+2)^{-1}$. In a separate work (Mbeng et al., arXiv:1911.12259) we have explicitly shown, exploiting a Jordan-Wigner transformation, that among the $2^{\\mathrm{P}}$ degenerate variational minima which can be found for this problem, all strictly satisfying the equality $\\epsilon^\\mathrm{res}_{\\mathrm{P}}=(2\\mathrm{P}+2)^{-1}$, one can construct a special {\\em regular} optimal solution, which is computationally optimal and does not require any prior knowledge about the spectral gap. We explicitly demonstrate here that such a schedule is adiabatic, in a digitized sense, and can therefore be interpreted as an optimized digitized-QA protocol. We also discuss and compare our bound on the residual energy to well-known results on the Kibble-Zurek mechanism behind a continuous-time QA. These findings help elucidating the intimate relation between digitized-QA, QAOA, and optimal Quantum Control.","authors":"Glen Bigan Mbeng, Rosario Fazio, Giuseppe Santoro"},"1908.07353":{"title":"A Hierarchy of Anyon Models Realised by Twists in Stacked Surface Codes","abstract":"Braiding defects in topological stabiliser codes can be used to fault-tolerantly implement logical operations. Twists are defects corresponding to the end-points of domain walls and are associated with symmetries of the anyon model of the code. We consider twists in multiple copies of the 2d surface code and identify necessary and sufficient conditions for considering these twists as anyons: namely that they must be self-inverse and that all charges which can be localised by the twist must be invariant under its associated symmetry. If both of these conditions are satisfied the twist and its set of localisable anyonic charges reproduce the behaviour of an anyonic model belonging to a hierarchy which generalises the Ising anyons. We show that the braiding of these twists results in either (tensor products of) the S gate or (tensor products of) the CZ gate. We also show that for any number of copies of the 2d surface code the application of H gates within a copy and CNOT gates between copies is sufficient to generate all possible twists.","authors":"T. R. Scruby, D. E. Browne"},"1908.09959":{"title":"The Overlap Gap Property in Principal Submatrix Recovery","abstract":"We study support recovery for a $k \\times k$ principal submatrix with elevated mean $\\lambda/N$, hidden in an $N\\times N$ symmetric mean zero Gaussian matrix. Here $\\lambda&gt;0$ is a universal constant, and we assume $k = N \\rho$ for some constant $\\rho \\in (0,1)$. We establish that {there exists a constant $C&gt;0$ such that} the MLE recovers a constant proportion of the hidden submatrix if $\\lambda {\\geq C} \\sqrt{\\frac{1}{\\rho} \\log \\frac{1}{\\rho}}$, {while such recovery is information theoretically impossible if $\\lambda = o( \\sqrt{\\frac{1}{\\rho} \\log \\frac{1}{\\rho}} )$}. The MLE is computationally intractable in general, and in fact, for $\\rho&gt;0$ sufficiently small, this problem is conjectured to exhibit a \\emph{statistical-computational gap}. To provide rigorous evidence for this, we study the likelihood landscape for this problem, and establish that for some $\\varepsilon&gt;0$ and $\\sqrt{\\frac{1}{\\rho} \\log \\frac{1}{\\rho} } \\ll \\lambda \\ll \\frac{1}{\\rho^{1/2 + \\varepsilon}}$, the problem exhibits a variant of the \\emph{Overlap-Gap-Property (OGP)}. As a direct consequence, we establish that a family of local MCMC based algorithms do not achieve optimal recovery. Finally, we establish that for $\\lambda &gt; 1/\\rho$, a simple spectral method recovers a constant proportion of the hidden submatrix.","authors":"David Gamarnik, Aukosh Jagannath, Subhabrata Sen"},"1910.08980":{"title":"Obstacles to State Preparation and Variational Optimization from Symmetry Protection","abstract":"Local Hamiltonians with topological quantum order exhibit highly entangled ground states that cannot be prepared by shallow quantum circuits. Here, we show that this property may extend to all low-energy states in the presence of an on-site $\\mathbb{Z}_2$ symmetry. This proves a version of the No Low-Energy Trivial States (NLTS) conjecture for a family of local Hamiltonians with symmetry protected topological order. A surprising consequence of this result is that the Goemans-Williamson algorithm outperforms the Quantum Approximate Optimization Algorithm (QAOA) for certain instances of MaxCut, at any constant level. We argue that the locality and symmetry of QAOA severely limits its performance. To overcome these limitations, we propose a non-local version of QAOA, and give numerical evidence that it significantly outperforms standard QAOA for frustrated Ising models on random 3-regular graphs.","authors":"Sergey Bravyi, Alexander Kliesch, Robert Koenig, Eugene Tang"},"1912.08854":{"title":"A Theory of Trotter Error","abstract":"The Lie-Trotter formula, together with its higher-order generalizations, provides a direct approach to decomposing the exponential of a sum of operators. Despite significant effort, the error scaling of such product formulas remains poorly understood. We develop a theory of Trotter error that overcomes the limitations of prior approaches based on truncating the Baker-Campbell-Hausdorff expansion. Our analysis directly exploits the commutativity of operator summands, producing tighter error bounds for both real- and imaginary-time evolutions. Whereas previous work achieves similar goals for systems with geometric locality or Lie-algebraic structure, our approach holds in general. We give a host of improved algorithms for digital quantum simulation and quantum Monte Carlo methods, including simulations of second-quantized plane-wave electronic structure, $k$-local Hamiltonians, rapidly decaying power-law interactions, clustered Hamiltonians, the transverse field Ising model, and quantum ferromagnets, nearly matching or even outperforming the best previous results. We obtain further speedups using the fact that product formulas can preserve the locality of the simulated system. Specifically, we show that local observables can be simulated with complexity independent of the system size for power-law interacting systems, which implies a Lieb-Robinson bound as a byproduct. Our analysis reproduces known tight bounds for first- and second-order formulas. Our higher-order bound overestimates the complexity of simulating a one-dimensional Heisenberg model with an even-odd ordering of terms by only a factor of $5$, and is close to tight for power-law interactions and other orderings of terms. This suggests that our theory can accurately characterize Trotter error in terms of both asymptotic scaling and constant prefactor.","authors":"Andrew M. Childs, Yuan Su, Minh C. Tran, Nathan Wiebe, Shuchen Zhu"},"2002.05693":{"title":"Classical Simulation of Noncontextual Pauli Hamiltonians","abstract":"Noncontextual Pauli Hamiltonians decompose into sets of Pauli terms to which joint values may be assigned without contradiction. We construct a quasi-quantized model for noncontextual Pauli Hamiltonians. Using this model, we give an algorithm to classically simulate noncontextual VQE. We also use the model to show that the noncontextual Hamiltonian problem is NP-complete. Finally, we explore the applicability of our quasi-quantized model as an approximate simulation tool for contextual Hamiltonians. These results support the notion of noncontextuality as classicality in near-term quantum algorithms.","authors":"William M. Kirby, Peter J. Love"},"2002.08953":{"title":"Predicting Many Properties of a Quantum System from Very Few Measurements","abstract":"Predicting properties of complex, large-scale quantum systems is essential for developing quantum technologies. We present an efficient method for constructing an approximate classical description of a quantum state using very few measurements of the state. This description, called a classical shadow, can be used to predict many different properties: order $\\log M$ measurements suffice to accurately predict $M$ different functions of the state with high success probability. The number of measurements is independent of the system size, and saturates information-theoretic lower bounds. Moreover, target properties to predict can be selected after the measurements are completed. We support our theoretical findings with extensive numerical experiments. We apply classical shadows to predict quantum fidelities, entanglement entropies, two-point correlation functions, expectation values of local observables, and the energy variance of many-body local Hamiltonians. The numerical results highlight the advantages of classical shadows relative to previously known methods.","authors":"Hsin-Yuan Huang, Richard Kueng, John Preskill"},"2002.11649":{"title":"Efficient phase-factor evaluation in quantum signal processing","abstract":"Quantum signal processing (QSP) is a powerful quantum algorithm to exactly implement matrix polynomials on quantum computers. Asymptotic analysis of quantum algorithms based on QSP has shown that asymptotically optimal results can in principle be obtained for a range of tasks, such as Hamiltonian simulation and the quantum linear system problem. A further benefit of QSP is that it uses a minimal number of ancilla qubits, which facilitates its implementation on near-to-intermediate term quantum architectures. However, there is so far no classically stable algorithm allowing computation of the phase factors that are needed to build QSP circuits. Existing methods require the usage of variable precision arithmetic and can only be applied to polynomials of relatively low degree. We present here an optimization based method that can accurately compute the phase factors using standard double precision arithmetic operations. We demonstrate the performance of this approach with applications to Hamiltonian simulation, eigenvalue filtering, and the quantum linear system problems. Our numerical results show that the optimization algorithm can find phase factors to accurately approximate polynomials of degree larger than $10,000$ with error below $10^{-12}$.","authors":"Yulong Dong, Xiang Meng, K. Birgitta Whaley, Lin Lin"},"2003.07419":{"title":"Polynomial scaling of QAOA for ground-state preparation of the fully-connected p-spin ferromagnet","abstract":"We show that the quantum approximate optimization algorithm (QAOA) can construct with polynomially scaling resources the ground state of the fully-connected p-spin Ising ferromagnet, a problem that notoriously poses severe difficulties to a Quantum Annealing (QA) approach, due to the exponentially small gaps encountered at first-order phase transition for ${\\rm p} \\ge 3$. For a target ground state at arbitrary transverse field, we find that an appropriate QAOA parameter initialization is necessary to achieve a good performance of the algorithm when the number of variational parameters $2{\\rm P}$ is much smaller than the system size ${\\rm N}$, because of the large number of sub-optimal local minima. Instead, when ${\\rm P}$ exceeds a critical value ${\\rm P}^*_{\\rm N} \\propto {\\rm N}$, the structure of the parameter space simplifies, as all minima become degenerate. This allows to achieve the ground state with perfect fidelity with a number of parameters scaling extensively with ${\\rm N}$, and with resources scaling polynomially with ${\\rm N}$.","authors":"Matteo M. Wauters, Glen Bigan Mbeng, Giuseppe E. Santoro"},"2004.11568":{"title":"Efficient Algorithms for Approximating Quantum Partition Functions","abstract":"We establish a polynomial-time approximation algorithm for partition functions of quantum spin models at high temperature. Our algorithm is based on the quantum cluster expansion of Neto\\v{c}n\\'y and Redig and the cluster expansion approach to designing algorithms due to Helmuth, Perkins, and Regts. Similar results have previously been obtained by related methods, and our main contribution is a simple and slightly sharper analysis for the case of pairwise interactions on bounded-degree graphs.","authors":"Ryan L. Mann, Tyler Helmuth"},"2005.02421":{"title":"Spoofing Linear Cross-Entropy Benchmarking in Shallow Quantum Circuits","abstract":"The linear cross-entropy benchmark (Linear XEB) has been used as a test for procedures simulating quantum circuits. Given a quantum circuit $C$ with $n$ inputs and outputs and purported simulator whose output is distributed according to a distribution $p$ over $\\{0,1\\}^n$, the linear XEB fidelity of the simulator is $\\mathcal{F}_{C}(p) = 2^n \\mathbb{E}_{x \\sim p} q_C(x) -1$ where $q_C(x)$ is the probability that $x$ is output from the distribution $C|0^n\\rangle$. A trivial simulator (e.g., the uniform distribution) satisfies $\\mathcal{F}_C(p)=0$, while Google's noisy quantum simulation of a 53 qubit circuit $C$ achieved a fidelity value of $(2.24\\pm0.21)\\times10^{-3}$ (Arute et. al., Nature'19). In this work we give a classical randomized algorithm that for a given circuit $C$ of depth $d$ with Haar random 2-qubit gates achieves in expectation a fidelity value of $\\Omega(\\tfrac{n}{L} \\cdot 15^{-d})$ in running time $\\textsf{poly}(n,2^L)$. Here $L$ is the size of the \\emph{light cone} of $C$: the maximum number of input bits that each output bit depends on. In particular, we obtain a polynomial-time algorithm that achieves large fidelity of $\\omega(1)$ for depth $O(\\sqrt{\\log n})$ two-dimensional circuits. To our knowledge, this is the first such result for two dimensional circuits of super-constant depth. Our results can be considered as an evidence that fooling the linear XEB test might be easier than achieving a full simulation of the quantum circuit.","authors":"Boaz Barak, Chi-Ning Chou, Xun Gao"},"2005.05832":{"title":"Creative Quantum Computing: Inverse FFT, Sound Synthesis, Adaptive Sequencing and Musical Composition","abstract":"Quantum computing is emerging as an alternative computing technology, which is built on the principles of subatomic physics. In spite of continuing progress in developing increasingly more sophisticated hardware and software, access to quantum computing still requires specialist expertise that is largely confined to research laboratories. Moreover, the target applications for these developments remain primarily scientific. This chapter introduces research aimed at improving this scenario. Our research is aimed at extending the range of applications of quantum computing towards the arts and creative applications, music being our point of departure. This chapter reports on initial outcomes, whereby quantum information processing controls an inverse Fast Fourier Transform (FFT) sound synthesizer and an adaptive musical sequencer. A composition called Zeno is presented to illustrate a practical real-world application.","authors":"Eduardo R. Miranda"},"2005.08747":{"title":"The Quantum Approximate Optimization Algorithm Needs to See the Whole Graph: Worst Case Examples","abstract":"The Quantum Approximate Optimization Algorithm can be applied to search problems on graphs with a cost function that is a sum of terms corresponding to the edges. When conjugating an edge term, the QAOA unitary at depth p produces an operator that depends only on the subgraph consisting of edges that are at most p away from the edge in question. On random d-regular graphs, with d fixed and with p a small constant time log n, these neighborhoods are almost all trees and so the performance of the QAOA is determined only by how it acts on an edge in the middle of tree. Both bipartite random d-regular graphs and general random d-regular graphs locally are trees so the QAOA's performance is the same on these two ensembles. Using this we can show that the QAOA with $(d-1)^{2p} &lt; n^A$ for any $A&lt;1$, can only achieve an approximation ratio of 1/2 for Max-Cut on bipartite random d-regular graphs for d large. For Maximum Independent Set, in the same setting, the best approximation ratio is a d-dependent constant that goes to 0 as d gets big.","authors":"Edward Farhi, David Gamarnik, Sam Gutmann"},"2005.11011":{"title":"Using models to improve optimizers for variational quantum algorithms","abstract":"Variational quantum algorithms are a leading candidate for early applications on noisy intermediate-scale quantum computers. These algorithms depend on a classical optimization outer-loop that minimizes some function of a parameterized quantum circuit. In practice, finite sampling error and gate errors make this a stochastic optimization with unique challenges that must be addressed at the level of the optimizer. The sharp trade-off between precision and sampling time in conjunction with experimental constraints necessitates the development of new optimization strategies to minimize overall wall clock time in this setting. In this work, we introduce two optimization methods and numerically compare their performance with common methods in use today. The methods are surrogate model-based algorithms designed to improve reuse of collected data. They do so by utilizing a least-squares quadratic fit of sampled function values within a moving trusted region to estimate the gradient or a policy gradient. To make fair comparisons between optimization methods, we develop experimentally relevant cost models designed to balance efficiency in testing and accuracy with respect to cloud quantum computing systems. The results here underscore the need to both use relevant cost models and optimize hyperparameters of existing optimization methods for competitive performance. The methods introduced here have several practical advantages in realistic experimental settings, and we have used one of them successfully in a separately published experiment on Google's Sycamore device.","authors":"Kevin J. Sung, Jiahao Yao, Matthew P. Harrigan, Nicholas C. Rubin, Zhang Jiang, Lin Lin, Ryan Babbush, Jarrod R. McClean"},"2006.09350":{"title":"Minimizing estimation runtime on noisy quantum computers","abstract":"The number of measurements demanded by hybrid quantum-classical algorithms such as the variational quantum eigensolver (VQE) is prohibitively high for many problems of practical value. For such problems, realizing quantum advantage will require methods which dramatically reduce this cost. Previous quantum algorithms that reduce the measurement cost (e.g. quantum amplitude and phase estimation) require error rates that are too low for near-term implementation. Here we propose methods that take advantage of the available quantum coherence to maximally enhance the power of sampling on noisy quantum devices, reducing measurement number and runtime compared to the standard sampling method of the variational quantum eigensolver (VQE). Our scheme derives inspiration from quantum metrology, phase estimation, and the more recent \"alpha-VQE\" proposal, arriving at a general formulation that is robust to error and does not require ancilla qubits. The central object of this method is what we call the \"engineered likelihood function\" (ELF), used for carrying out Bayesian inference. We show how the ELF formalism enhances the rate of information gain in sampling as the physical hardware transitions from the regime of noisy intermediate-scale quantum computers into that of quantum error corrected ones. This technique speeds up a central component of many quantum algorithms, with applications including chemistry, materials, finance, and beyond. Similar to VQE, we expect small-scale implementations to be realizable on today's quantum devices.","authors":"Guoming Wang, Dax Enshan Koh, Peter D. Johnson, Yudong Cao"},"2008.00466":{"title":"Complexity continuum within Ising formulation of NP problems","abstract":"A promising approach to achieve computational supremacy over the classical von Neumann architecture explores classical and quantum hardware as Ising machines. The minimisation of the Ising Hamiltonian is known to be NP-hard problem for certain interaction matrix classes, yet not all problem instances are equivalently hard to optimise. We propose to identify computationally simple instances with an `optimisation simplicity criterion'. Such optimisation simplicity can be found for a wide range of models from spin glasses to k-regular maximum cut problems. Many optical, photonic, and electronic systems are neuromorphic architectures that can naturally operate to optimise problems satisfying this criterion and, therefore, such problems are often chosen to illustrate the computational advantages of new Ising machines. We further probe an intermediate complexity for sparse and dense models by analysing circulant coupling matrices, that can be `rewired' to introduce greater complexity. A compelling approach for distinguishing easy and hard instances within the same NP-hard class of problems can be a starting point in developing a standardised procedure for the performance evaluation of emerging physical simulators and physics-inspired algorithms.","authors":"Kirill P. Kalinin, Natalia G. Berloff"},"2008.04628":{"title":"Bolometer operating at the threshold for circuit quantum electrodynamics","abstract":"Radiation sensors based on the heating effect of the absorbed radiation are typically relatively simple to operate and flexible in terms of the input frequency. Consequently, they are widely applied, for example, in gas detection, security, THz imaging, astrophysical observations, and medical applications. A new spectrum of important applications is currently emerging from quantum technology and especially from electrical circuits behaving quantum mechanically. This circuit quantum electrodynamics (cQED) has given rise to unprecedented single-photon detectors and a quantum computer supreme to the classical supercomputers in a certain task. Thermal sensors are appealing in enhancing these devices since they are not plagued by quantum noise and are smaller, simpler, and consume about six orders of magnitude less power than the commonly used traveling-wave parametric amplifiers. However, despite great progress in the speed and noise levels of thermal sensors, no bolometer to date has proven fast and sensitive enough to provide advantages in cQED. Here, we experimentally demonstrate a bolometer surpassing this threshold with a noise equivalent power of $30\\, \\rm{zW}/\\sqrt{\\rm{Hz}}$ on par with the current record while providing two-orders of magnitude shorter thermal time constant of 500 ns. Importantly, both of these characteristic numbers have been measured directly from the same device, which implies a faithful estimation of the calorimetric energy resolution of a single 30-GHz photon. These improvements stem from the utilization of a graphene monolayer as the active material with extremely low specific heat. The minimum demonstrated time constant of 200 ns falls greatly below the state-of-the-art dephasing times of roughly 100 {\\mu}s for superconducting qubits and meets the timescales of contemporary readout schemes thus enabling the utilization of thermal detectors in cQED.","authors":"R. Kokkoniemi, J. -P. Girard, D. Hazra, A. Laitinen, J. Govenius, R. E. Lake, I. Sallinen, V. Vesterinen, P. Hakonen, M. Möttönen"},"2009.07450":{"title":"On the Hardness of Detecting Macroscopic Superpositions","abstract":"When is decoherence \"effectively irreversible\"? Here we examine this central question of quantum foundations using the tools of quantum computational complexity. We prove that, if one had a quantum circuit to determine if a system was in an equal superposition of two orthogonal states (for example, the $|$Alive$\\rangle$ and $|$Dead$\\rangle$ states of Schr\\\"{o}dinger's cat), then with only a slightly larger circuit, one could also $\\mathit{swap}$ the two states (e.g., bring a dead cat back to life). In other words, observing interference between the $|$Alive$\\rangle$and $|$Dead$\\rangle$ states is a \"necromancy-hard\" problem, technologically infeasible in any world where death is permanent. As for the converse statement (i.e., ability to swap implies ability to detect interference), we show that it holds modulo a single exception, involving unitaries that (for example) map $|$Alive$\\rangle$ to $|$Dead$\\rangle$ but $|$Dead$\\rangle$ to -$|$Alive$\\rangle$. We also show that these statements are robust---i.e., even a $\\mathit{partial}$ ability to observe interference implies partial swapping ability, and vice versa. Finally, without relying on any unproved complexity conjectures, we show that all of these results are quantitatively tight. Our results have possible implications for the state dependence of observables in quantum gravity, the subject that originally motivated this study.","authors":"Scott Aaronson, Yosi Atia, Leonard Susskind"},"2009.11170":{"title":"Explicit construction of exact unitary designs","abstract":"The purpose of this paper is to give explicit constructions of unitary $t$-designs in the unitary group $U(d)$ for all $t$ and $d$. It seems that the explicit constructions were so far known only for very special cases. Here explicit construction means that the entries of the unitary matrices are given by the values of elementary functions at the root of some given polynomials. We will discuss what are the best such unitary $4$-designs in $U(4)$ obtained by these methods. Indeed we give an inductive construction of designs on compact groups by using Gelfand pairs $(G,K)$. Note that $(U(n),U(m) \\times U(n-m))$ is a Gelfand pair. By using the zonal spherical functions for $(G,K)$, we can construct designs on $G$ from designs on $K$. We remark that our proofs use the representation theory of compact groups crucially. We also remark that this method can be applied to the orthogonal groups $O(d)$, and thus provides another explicit construction of spherical $t$-designs on the $d$ dimensional sphere $S^{d-1}$ by the induction on $d$.","authors":"Eiichi Bannai, Yoshifumi Nakata, Takayuki Okuda, Da Zhao"},"2009.12472":{"title":"How will quantum computers provide an industrially relevant computational advantage in quantum chemistry?","abstract":"Numerous reports claim that quantum advantage, which should emerge as a direct consequence of the advent of quantum computers, will herald a new era of chemical research because it will enable scientists to perform the kinds of quantum chemical simulations that have not been possible before. Such simulations on quantum computers, promising a significantly greater accuracy and speed, are projected to exert a great impact on the way we can probe reality, predict the outcomes of chemical experiments, and even drive design of drugs, catalysts, and materials. In this work we review the current status of quantum hardware and algorithm theory and examine whether such popular claims about quantum advantage are really going to be transformative. We go over subtle complications of quantum chemical research that tend to be overlooked in discussions involving quantum computers. We estimate quantum computer resources that will be required for performing calculations on quantum computers with chemical accuracy for several types of molecules. In particular, we directly compare the resources and timings associated with classical and quantum computers for the molecules H$_2$ for increasing basis set sizes, and Cr$_2$ for a variety of complete active spaces (CAS) within the scope of the CASCI and CASSCF methods. The results obtained for the chromium dimer enable us to estimate the size of the active space at which computations of non-dynamic correlation on a quantum computer should take less time than analogous computations on a classical computer. Using this result, we speculate on the types of chemical applications for which the use of quantum computers would be both beneficial and relevant to industrial applications in the short term.","authors":"V. E. Elfving, B. W. Broer, M. Webber, J. Gavartin, M. D. Halls, K. P. Lorton, A. Bochevarov"},"2012.02022":{"title":"Determining QMC simulability with geometric phases","abstract":"Although stoquastic Hamiltonians are known to be simulable via sign-problem-free quantum Monte Carlo (QMC) techniques, the non-stoquasticity of a Hamiltonian does not necessarily imply the existence of a QMC sign problem. We give a sufficient and necessary condition for the QMC-simulability of Hamiltonians in a fixed basis in terms of geometric phases associated with the chordless cycles of the weighted graphs whose adjacency matrices are the Hamiltonians. We use our findings to provide a construction for non-stoquastic, yet sign-problem-free and hence QMC-simulable, quantum many-body models. We also demonstrate why the simulation of truly sign-problematic models using the QMC weights of the stoquasticized Hamiltonian is generally sub-optimal. We offer a superior alternative.","authors":"Itay Hen"},"2012.03924":{"title":"Generation of High-Resolution Handwritten Digits with an Ion-Trap Quantum Computer","abstract":"Generating high-quality data (e.g. images or video) is one of the most exciting and challenging frontiers in unsupervised machine learning. Utilizing quantum computers in such tasks to potentially enhance conventional machine learning algorithms has emerged as a promising application, but poses big challenges due to the limited number of qubits and the level of gate noise in available devices. In this work, we provide the first practical and experimental implementation of a quantum-classical generative algorithm capable of generating high-resolution images of handwritten digits with state-of-the-art gate-based quantum computers. In our quantum-assisted machine learning framework, we implement a quantum-circuit based generative model to learn and sample the prior distribution of a Generative Adversarial Network. We introduce a multi-basis technique which leverages the unique possibility of measuring quantum states in different bases, hence enhancing the expressibility of the prior distribution. We train this hybrid algorithm on an ion-trap device based on $^{171}$Yb$^{+}$ ion qubits to generate high-quality images and quantitatively outperform comparable classical Generative Adversarial Networks trained on the popular MNIST data set for handwritten digits.","authors":"Manuel S. Rudolph, Ntwali Bashige Toussaint, Amara Katabarwa, Sonika Johri, Borja Peropadre, Alejandro Perdomo-Ortiz"},"2012.07825":{"title":"Analyzing the Performance of Variational Quantum Factoring on a Superconducting Quantum Processor","abstract":"In the near-term, hybrid quantum-classical algorithms hold great potential for outperforming classical approaches. Understanding how these two computing paradigms work in tandem is critical for identifying areas where such hybrid algorithms could provide a quantum advantage. In this work, we study a QAOA-based quantum optimization algorithm by implementing the Variational Quantum Factoring (VQF) algorithm. We execute experimental demonstrations using a superconducting quantum processor and investigate the trade-off between quantum resources (number of qubits and circuit depth) and the probability that a given biprime is successfully factored. In our experiments, the integers 1099551473989, 3127, and 6557 are factored with 3, 4, and 5 qubits, respectively, using a QAOA ansatz with up to 8 layers and we are able to identify the optimal number of circuit layers for a given instance to maximize success probability. Furthermore, we demonstrate the impact of different noise sources on the performance of QAOA and reveal the coherent error caused by the residual ZZ-coupling between qubits as a dominant source of error in the superconducting quantum processor.","authors":"Amir H. Karamlou, William A. Simon, Amara Katabarwa, Travis L. Scholten, Borja Peropadre, Yudong Cao"},"2101.05513":{"title":"Local classical MAX-CUT algorithm outperforms $p=2$ QAOA on high-girth regular graphs","abstract":"The $p$-stage Quantum Approximate Optimization Algorithm (QAOA$_p$) is a promising approach for combinatorial optimization on noisy intermediate-scale quantum (NISQ) devices, but its theoretical behavior is not well understood beyond $p=1$. We analyze QAOA$_2$ for the maximum cut problem (MAX-CUT), deriving a graph-size-independent expression for the expected cut fraction on any $D$-regular graph of girth $&gt; 5$ (i.e. without triangles, squares, or pentagons). We show that for all degrees $D \\ge 2$ and every $D$-regular graph $G$ of girth $&gt; 5$, QAOA$_2$ has a larger expected cut fraction than QAOA$_1$ on $G$. However, we also show that there exists a $2$-local randomized classical algorithm $A$ such that $A$ has a larger expected cut fraction than QAOA$_2$ on all $G$. This supports our conjecture that for every constant $p$, there exists a local classical MAX-CUT algorithm that performs as well as QAOA$_p$ on all graphs.","authors":"Kunal Marwaha"},"2101.07267":{"title":"Training variational quantum algorithms is NP-hard -- even for logarithmically many qubits and free fermionic systems","abstract":"Variational quantum algorithms (VQAs) are proposed to solve relevant computational problems on near term quantum devices. Popular versions are variational quantum eigensolvers (VQEs) and quantum approximate optimization algorithms (QAOAs) that solve ground state problems from quantum chemistry and binary optimization problems, respectively. They are based on the idea to use a classical computer to train a parameterized quantum circuit. We show that the corresponding classical optimization problems are NP-hard. Moreover, the hardness is robust in the sense that for every polynomial time algorithm, there exists instances for which the relative error resulting from the classical optimization problem can be arbitrarily large, unless P = NP. Even for classically tractable systems, composed of only logarithmically many qubits or free fermions, we show that the optimization is NP-hard. This elucidates that the classical optimization is intrinsically hard and does not merely inherit the hardness from the ground state problem. Our analysis shows that the training landscape can have many far from optimal persistent local minima. This means gradient and higher order decent algorithms will generally converge to far from optimal solutions.","authors":"Lennart Bittel, Martin Kliesch"},"2101.10279":{"title":"QFold: Quantum Walks and Deep Learning to Solve Protein Folding","abstract":"We develop quantum computational tools to predict how proteins fold in 3D, one of the most important problems in current biochemical research. We explain how to combine recent deep learning advances with the well known technique of quantum walks applied to a Metropolis algorithm. The result, QFold, is a fully scalable hybrid quantum algorithm that in contrast to previous quantum approaches does not require a lattice model simplification and instead relies on the much more realistic assumption of parameterization in terms of torsion angles of the amino acids. We compare it with its classical analog for different annealing schedules and find a polynomial quantum advantage, and validate a proof-of-concept realization of the quantum Metropolis in IBMQ Casablanca quantum processor.","authors":"P A M Casares, Roberto Campos, M A Martin-Delgado"},"2102.03248":{"title":"Quantum computing hardware in the cloud: Should a computational chemist care?","abstract":"Within the last decade much progress has been made in the experimental realisation of quantum computing hardware based on a variety of physical systems. Rapid progress has been fuelled by the conviction that sufficiently powerful quantum machines will herald enormous computational advantages in many fields, including chemical research. A quantum computer capable of simulating the electronic structures of complex molecules would be a game changer for the design of new drugs and materials. Given the potential implications of this technology, there is a need within the chemistry community to keep abreast with the latest developments as well as becoming involved in experimentation with quantum prototypes. To facilitate this, here we review the types of quantum computing hardware that have been made available to the public through cloud services. We focus on three architectures, namely superconductors, trapped ions and semiconductors. For each one we summarise the basic physical operations, requirements and performance. We discuss to what extent each system has been used for molecular chemistry problems and highlight the most pressing hardware issues to be solved for a chemistry-relevant quantum advantage to eventually emerge.","authors":"A. Rossi, P. G. Baity, V. M. Schäfer, M. Weides"},"2102.12951":{"title":"An algorithm to factorize quantum walks into shift and coin operations","abstract":"We provide an algorithm that factorizes one-dimensional quantum walks into a protocol of two basic operations: A fixed conditional shift that transports particles between cells and suitable coin operators that act locally in each cell. This allows to tailor quantum walk protocols to any experimental setup by rephrasing it on the cell structure determined by the experimental limitations. We give the example of a walk defined on a qutrit chain compiled to run an a qubit chain.","authors":"C. Cedzich, T. Geib, R. F. Werner"},"2103.01928":{"title":"A taxonomy of small Markovian errors","abstract":"Errors in quantum logic gates are usually modeled by quantum process matrices (CPTP maps). But process matrices can be opaque, and unwieldy. We show how to transform a gate's process matrix into an error generator that represents the same information more usefully. We construct a basis of simple and physically intuitive elementary error generators, classify them, and show how to represent any gate's error generator as a mixture of elementary error generators with various rates. Finally, we show how to build a large variety of reduced models for gate errors by combining elementary error generators and/or entire subsectors of generator space. We conclude with a few examples of reduced models, including one with just $9N^2$ parameters that describes almost all commonly predicted errors on an N-qubit processor.","authors":"Robin Blume-Kohout, Marcus P. da Silva, Erik Nielsen, Timothy Proctor, Kenneth Rudinger, Mohan Sarovar, Kevin Young"},"2103.08215":{"title":"Electronic Structure in a Fixed Basis is QMA-complete","abstract":"Finding the ground state energy of electrons subject to an external electric field is a fundamental problem in computational chemistry. We prove that this electronic-structure problem, when restricted to a fixed single-particle basis and fixed number of electrons, is QMA-complete. Schuch and Verstraete have shown hardness for the electronic-structure problem with an additional site-specific external magnetic field, but without the restriction to a fixed basis. In their reduction, a local Hamiltonian on qubits is encoded in the site-specific magnetic field. In our reduction, the local Hamiltonian is encoded in the choice of spatial orbitals used to discretize the electronic-structure Hamiltonian. As a step in their proof, Schuch and Verstraete show a reduction from the antiferromagnetic Heisenberg Hamiltonian to the Fermi-Hubbard Hamiltonian. We combine this reduction with the fact that the antiferromagnetic Heisenberg Hamiltonian is QMA-hard to observe that the Fermi-Hubbard Hamiltonian on generic graphs is QMA-hard, even when all the hopping coefficients have the same sign. We then reduce from Fermi-Hubbard by showing that an instance of Fermi-Hubbard can be closely approximated by an instance of the Electronic-Structure Hamiltonian in a fixed basis. Finally, we show that estimating the energy of the lowest-energy Slater-determinant state (i.e., the Hartree-Fock state) is NP-complete for the Electronic-Structure Hamiltonian in a fixed basis.","authors":"Bryan O'Gorman, Sandy Irani, James Whitfield, Bill Fefferman"},"2103.11976":{"title":"Parameter Concentration in Quantum Approximate Optimization","abstract":"The quantum approximate optimization algorithm (QAOA) has become a cornerstone of contemporary quantum applications development. In QAOA, a quantum circuit is trained -- by repeatedly adjusting circuit parameters -- to solve a problem. Several recent findings have reported parameter concentration effects in QAOA and their presence has become one of folklore: while empirically observed, the concentrations have not been defined and analytical approaches remain scarce, focusing on limiting system and not considering parameter scaling as system size increases. We found that optimal QAOA circuit parameters concentrate as an inverse polynomial in the problem size, providing an optimistic result for improving circuit training. Our results are analytically demonstrated for variational state preparations at $p=1,2$ (corresponding to 2 and 4 tunable parameters respectively). The technique is also applicable for higher depths and the concentration effect is cross verified numerically. Parameter concentrations allow for training on a fraction $w &lt; n$ of qubits to assert that these parameters are nearly optimal on $n$ qubits. Clearly this effect has significant practical importance.","authors":"V. Akshay, D. Rabinovich, E. Campos, J. Biamonte"},"2103.17065":{"title":"Classically optimal variational quantum algorithms","abstract":"Hybrid quantum-classical algorithms, such as variational quantum algorithms (VQA), are suitable for implementation on NISQ computers. In this Letter we expand an implicit step of VQAs: the classical pre-computation subroutine which can non-trivially use classical algorithms to simplify, transform, or specify problem instance-specific variational quantum circuits. In VQA there is a trade-off between quality of solution and difficulty of circuit construction and optimization. In one extreme, we find VQA for MAXCUT which are exact, but circuit design or variational optimization is NP-HARD. At the other extreme are low depth VQA, such as QAOA, with tractable circuit construction and optimization but poor approximation ratios. Combining these two we define the Spanning Tree QAOA (ST-QAOA) to solve MAXCUT, which uses an ansatz whose structure is derived from an approximate classical solution and achieves the same performance guarantee as the classical algorithm and hence can outperform QAOA at low depth. In general, we propose integrating these classical pre-computation subroutines into VQA to improve heuristic or guaranteed performance.","authors":"Jonathan Wurtz, Peter Love"},"2104.01205":{"title":"Demonstration of Shor encoding on a trapped-ion quantum computer","abstract":"Fault-tolerant quantum error correction (QEC) is crucial for unlocking the true power of quantum computers. QEC codes use multiple physical qubits to encode a logical qubit, which is protected against errors at the physical qubit level. Here we use a trapped ion system to experimentally prepare $m$-qubit GHZ states and sample the measurement results to construct $m\\times m$ logical states of the $[[m^2,1,m]]$ Shor code, up to $m=7$. The synthetic logical fidelity shows how deeper encoding can compensate for additional gate errors in state preparation for larger logical states. However, the optimal code size depends on the physical error rate and we find that $m=5$ has the best performance in our system. We further realize the direct logical encoding of the $[[9,1,3]]$ Shor code on nine qubits in a thirteen-ion chain for comparison, with $98.8(1)\\%$ and $98.5(1)\\%$ fidelity for state $\\left\\vert\\pm\\right\\rangle_L$, respectively.","authors":"Nhung H. Nguyen, Muyuan Li, Alaina M. Green, Cinthia Huerta Alderete, Yingyue Zhu, Daiwei Zhu, Kenneth R. Brown, Norbert M. Linke"},"2105.01193":{"title":"Improved approximation algorithms for bounded-degree local Hamiltonians","abstract":"We consider the task of approximating the ground state energy of two-local quantum Hamiltonians on bounded-degree graphs. Most existing algorithms optimize the energy over the set of product states. Here we describe a family of shallow quantum circuits that can be used to improve the approximation ratio achieved by a given product state. The algorithm takes as input an $n$-qubit product state $|v\\rangle$ with mean energy $e_0=\\langle v|H|v\\rangle$ and variance $\\mathrm{Var}=\\langle v|(H-e_0)^2|v\\rangle$, and outputs a state with an energy that is lower than $e_0$ by an amount proportional to $\\mathrm{Var}^2/n$. In a typical case, we have $\\mathrm{Var}=\\Omega(n)$ and the energy improvement is proportional to the number of edges in the graph. When applied to an initial random product state, we recover and generalize the performance guarantees of known algorithms for bounded-occurrence classical constraint satisfaction problems. We extend our results to $k$-local Hamiltonians and entangled initial states.","authors":"Anurag Anshu, David Gosset, Karen J. Morenz Korol, Mehdi Soleimanifar"},"2105.05500":{"title":"Test of Quantumness with Small-Depth Quantum Circuits","abstract":"Recently Brakerski, Christiano, Mahadev, Vazirani and Vidick (FOCS 2018) have shown how to construct a test of quantumness based on the learning with errors (LWE) assumption: a test that can be solved efficiently by a quantum computer but cannot be solved by a classical polynomial-time computer under the LWE assumption. This test has lead to several cryptographic applications. In particular, it has been applied to producing certifiable randomness from a single untrusted quantum device, self-testing a single quantum device and device-independent quantum key distribution. In this paper, we show that this test of quantumness, and essentially all the above applications, can actually be implemented by a very weak class of quantum circuits: constant-depth quantum circuits combined with logarithmic-depth classical computation. This reveals novel complexity-theoretic properties of this fundamental test of quantumness and gives new concrete evidence of the superiority of small-depth quantum circuits over classical computation.","authors":"Shuichi Hirahara, François Le Gall"},"2105.06996":{"title":"Analytical Framework for Quantum Alternating Operator Ansätze","abstract":"We develop a framework for analyzing layered quantum algorithms such as quantum alternating operator ans\\\"atze. Our framework relates quantum cost gradient operators, derived from the cost and mixing Hamiltonians, to classical cost difference functions that reflect cost function neighborhood structure. By considering QAOA circuits from the Heisenberg picture, we derive exact general expressions for expectation values as series expansions in the algorithm parameters, cost gradient operators, and cost difference functions. This enables novel interpretability and insight into QAOA behavior in various parameter regimes. For single- level QAOA1 we show the leading-order changes in the output probabilities and cost expectation value explicitly in terms of classical cost differences, for arbitrary cost functions. This demonstrates that, for sufficiently small positive parameters, probability flows from lower to higher cost states on average. By selecting signs of the parameters, we can control the direction of flow. We use these results to derive a classical random algorithm emulating QAOA1 in the small-parameter regime, i.e., that produces bitstring samples with the same probabilities as QAOA1 up to small error. For deeper QAOAp circuits we apply our framework to derive analogous and additional results in several settings. In particular we show QAOA always beats random guessing. We describe how our framework incorporates cost Hamiltonian locality for specific problem classes, including causal cone approaches, and applies to QAOA performance analysis with arbitrary parameters. We illuminate our results with a number of examples including applications to QUBO problems, MaxCut, and variants of MaxSat. We illustrate the application to QAOA circuits using mixing unitaries beyond the transverse-field mixer through two examples of constrained optimization, Max Independent Set and Graph Coloring.","authors":"Stuart Hadfield, Tad Hogg, Eleanor G. Rieffel"},"2106.05900":{"title":"Classical algorithms and quantum limitations for maximum cut on high-girth graphs","abstract":"We study the performance of local quantum algorithms such as the Quantum Approximate Optimization Algorithm (QAOA) for the maximum cut problem, and their relationship to that of classical algorithms. (1) We prove that every (quantum or classical) one-local algorithm achieves on $D$-regular graphs of girth $&gt; 5$ a maximum cut of at most $1/2 + C/\\sqrt{D}$ for $C=1/\\sqrt{2} \\approx 0.7071$. This is the first such result showing that one-local algorithms achieve a value bounded away from the true optimum for random graphs, which is $1/2 + P_*/\\sqrt{D} + o(1/\\sqrt{D})$ for $P_* \\approx 0.7632$. (2) We show that there is a classical $k$-local algorithm that achieves a value of $1/2 + C/\\sqrt{D} - O(1/\\sqrt{k})$ for $D$-regular graphs of girth $&gt; 2k+1$, where $C = 2/\\pi \\approx 0.6366$. This is an algorithmic version of the existential bound of Lyons and is related to the algorithm of Aizenman, Lebowitz, and Ruelle (ALR) for the Sherrington-Kirkpatrick model. This bound is better than that achieved by the one-local and two-local versions of QAOA on high-girth graphs. (3) Through computational experiments, we give evidence that the ALR algorithm achieves better performance than constant-locality QAOA for random $D$-regular graphs, as well as other natural instances, including graphs that do have short cycles. Our experimental work suggests that it could be possible to extend beyond our theoretical constraints. This points at the tantalizing possibility that $O(1)$-local quantum maximum-cut algorithms might be *pointwise dominated* by polynomial-time classical algorithms, in the sense that there is a classical algorithm outputting cuts of equal or better quality *on every possible instance*. This is in contrast to the evidence that polynomial-time algorithms cannot simulate the probability distributions induced by local quantum algorithms.","authors":"Boaz Barak, Kunal Marwaha"},"2106.10522":{"title":"Quantum computing 40 years later","abstract":"Forty years ago, Richard Feynman proposed harnessing quantum physics to build a more powerful kind of computer. Realizing Feynman's vision is one of the grand challenges facing 21st century science and technology. In this article, we'll recall Feynman's contribution that launched the quest for a quantum computer, and assess where the field stands 40 years later.","authors":"John Preskill"},"2106.12587":{"title":"Rényi entropy of magic","abstract":"We introduce a novel measure for the quantum property commonly known as $magic$ by considering the R\\'enyi entropy of the probability distribution associated to a pure quantum state given by the square of the expectation value of Pauli strings in that state. We show that this is a good measure of magic from the point of view of resource theory and show bounds with other known measures of magic. The R\\'enyi entropy of magic has the advantage of being easily computable because it does not need a minimization procedure. We define the magic power of a unitary operator as the average entropy of magic attainable by the action of this operator on the magic-free states, that is, stabilizer states, and show the basic properties of this quantity. As an application, we show that the magic power is intimately connected to out-of-time-order correlation functions and that maximal levels of magic are necessary for quantum chaos.","authors":"Lorenzo Leone, Salvatore F. E. Oliviero, Alioscia Hamma"},"2108.03283":{"title":"An Algebraic Quantum Circuit Compression Algorithm for Hamiltonian Simulation","abstract":"Quantum computing is a promising technology that harnesses the peculiarities of quantum mechanics to deliver computational speedups for some problems that are intractable to solve on a classical computer. Current generation noisy intermediate-scale quantum (NISQ) computers are severely limited in terms of chip size and error rates. Shallow quantum circuits with uncomplicated topologies are essential for successful applications in the NISQ era. Based on matrix analysis, we derive localized circuit transformations to efficiently compress quantum circuits for simulation of certain spin Hamiltonians known as free fermions. The depth of the compressed circuits is independent of simulation time and grows linearly with the number of spins. The proposed numerical circuit compression algorithm behaves backward stable and scales cubically in the number of spins enabling circuit synthesis beyond $\\mathcal{O}(10^3)$ spins. The resulting quantum circuits have a simple nearest-neighbor topology, which makes them ideally suited for NISQ devices.","authors":"Daan Camps, Efekan Kökcü, Lindsay Bassman, Wibe A. de Jong, Alexander F. Kemper, Roel Van Beeumen"},"cond-mat/0603695":{"title":"Quantum Logic Processor: A Mach Zehnder Interferometer based Approach","abstract":"Quantum Logic Processors can be implemented with Mach Zehnder Interferometer(MZI) configurations for the Quantum logic operations and gates. In this paper, its implementation for both optical and electronic system has been presented. The correspondence between Jones matrices for photon polarizations and Pauli spin matrices for electrons gives a representation of all the unitary matrices for the quantum gate operations. A novel quantum computation system based on a Electronic Mach Zehnder Interferometer(MZI) has also been proposed. It uses the electron spin as the primary qubit. Rashba effect is used to create Unitary transforms on spin qubits. A mesoscopic Stern Gerlach apparatus can be used for both spin injection and detection. An intertwined nanowire design is used for the MZI. The system can implement all single and double qubit gates. It can easily be coupled to form an array. Thus the Quantum Logic Processor (QLP) can be built using the system as its prototype.","authors":"Angik Sarkar, T. K. Bhattacharyya, Ajay Patwardhan"},"hep-ph/9506229":{"title":"The Pooltable Analogy to Axion Physics","abstract":"An imaginary character named TSP finds himself in a playroom whose floor is tilted to one side. However, the pooltable in the playroom is horizontal. TSP wonders how this can be. In doing so, he embarks upon an intellectual journey which parallels that which has been travelled during the past two decades by physicists interested in the Strong $CP$ Problem and axion physics.","authors":"Pierre Sikivie"},"quant-ph/0602063":{"title":"Topological Quantum Error Correction with Optimal Encoding Rate","abstract":"We prove the existence of topological quantum error correcting codes with encoding rates $k/n$ asymptotically approaching the maximum possible value. Explicit constructions of these topological codes are presented using surfaces of arbitrary genus. We find a class of regular toric codes that are optimal. For physical implementations, we present planar topological codes.","authors":"H. Bombin, M. A. Martin-Delgado"},"1908.03740":{"title":"Permutation Matrix Representation Quantum Monte Carlo","abstract":"We present a quantum Monte Carlo algorithm for the simulation of general quantum and classical many-body models within a single unifying framework. The algorithm builds on a power series expansion of the quantum partition function in its off-diagonal terms and is both parameter-free and Trotter error-free. In our approach, the quantum dimension consists of products of elements of a permutation group. As such, it allows for the study of a very wide variety of models on an equal footing. To demonstrate the utility of our technique, we use it to clarify the emergence of the sign problem in the simulations of non-stoquastic physical models. We showcase the flexibility of our algorithm and the advantages it offers over existing state-of-the-art by simulating transverse-field Ising model Hamiltonians and comparing the performance of our technique against that of the stochastic series expansion algorithm. We also study a transverse-field Ising model augmented with randomly chosen two-body transverse-field interactions.","authors":"Lalit Gupta, Tameem Albash, Itay Hen"},"2006.02539":{"title":"Quantum Algorithm for Simulating Hamiltonian Dynamics with an Off-diagonal Series Expansion","abstract":"We propose an efficient quantum algorithm for simulating the dynamics of general Hamiltonian systems. Our technique is based on a power series expansion of the time-evolution operator in its off-diagonal terms. The expansion decouples the dynamics due to the diagonal component of the Hamiltonian from the dynamics generated by its off-diagonal part, which we encode using the linear combination of unitaries technique. Our method has an optimal dependence on the desired precision and, as we illustrate, generally requires considerably fewer resources than the current state-of-the-art. We provide an analysis of resource costs for several sample models.","authors":"Amir Kalev, Itay Hen"},"2009.07268":{"title":"An improved quantum-inspired algorithm for linear regression","abstract":"We give a classical algorithm for linear regression analogous to the quantum matrix inversion algorithm [Harrow, Hassidim, and Lloyd, Physical Review Letters'09] for low-rank matrices [Wossnig et al., Physical Review Letters'18], when the input matrix $A$ is stored in a data structure applicable for QRAM-based state preparation. Namely, given an $A \\in \\mathbb{C}^{m\\times n}$ with minimum singular value $\\sigma$ and which supports certain efficient $\\ell_2$-norm importance sampling queries, along with a $b \\in \\mathbb{C}^m$, we can output a description of an $x \\in \\mathbb{C}^n$ such that $\\|x - A^+b\\| \\leq \\varepsilon\\|A^+b\\|$ in $\\tilde{\\mathcal{O}}\\Big(\\frac{\\|A\\|_{\\mathrm{F}}^6\\|A\\|^2}{\\sigma^8\\varepsilon^4}\\Big)$ time, improving on previous \"quantum-inspired\" algorithms in this line of research by a factor of $\\frac{\\|A\\|^{14}}{\\sigma^{14}\\varepsilon^2}$ [Chia et al., STOC'20]. The algorithm is stochastic gradient descent, and the analysis bears similarities to those of optimization algorithms for regression in the usual setting [Gupta and Sidford, NeurIPS'18]. Unlike earlier works, this is a promising avenue that could lead to feasible implementations of classical regression in a quantum-inspired setting, for comparison against future quantum computers.","authors":"András Gilyén, Zhao Song, Ewin Tang"},"0704.0771":{"title":"Suppression of 1/f noise in one-qubit systems","abstract":"We investigate the generation of quantum operations for one-qubit systems under classical noise with 1/f^\\alpha power spectrum, where 2&gt;\\alpha &gt; 0. We present an efficient way to approximate the noise with a discrete multi-state Markovian fluctuator. With this method, the average temporal evolution of the qubit density matrix under 1/f^\\alpha noise can be feasibly determined from recently derived deterministic master equations. We obtain qubit operations such as quantum memory and the NOT}gate to high fidelity by a gradient based optimization algorithm. For the NOT gate, the computed fidelities are qualitatively similar to those obtained earlier for random telegraph noise. In the case of quantum memory however, we observe a nonmonotonic dependency of the fidelity on the operation time, yielding a natural access rate of the memory.","authors":"Pekko Kuopanportti, Mikko Mottonen, Ville Bergholm, Olli-Pentti Saira, Jun Zhang, K. Birgitta Whaley"},"2108.10457":{"title":"A Fault-Tolerant Honeycomb Memory","abstract":"Recently, Hastings &amp; Haah introduced a quantum memory defined on the honeycomb lattice. Remarkably, this honeycomb code assembles weight-six parity checks using only two-local measurements. The sparse connectivity and two-local measurements are desirable features for certain hardware, while the weight-six parity checks enable robust performance in the circuit model. In this work, we quantify the robustness of logical qubits preserved by the honeycomb code using a correlated minimum-weight perfect-matching decoder. Using Monte Carlo sampling, we estimate the honeycomb code's threshold in different error models, and project how efficiently it can reach the \"teraquop regime\" where trillions of quantum logical operations can be executed reliably. We perform the same estimates for the rotated surface code, and find a threshold of $0.2\\%-0.3\\%$ for the honeycomb code compared to a threshold of $0.5\\%-0.7\\%$ for the surface code in a controlled-not circuit model. In a circuit model with native two-body measurements, the honeycomb code achieves a threshold of $1.5\\% &lt; p &lt;2.0\\%$, where $p$ is the collective error rate of the two-body measurement gate - including both measurement and correlated data depolarization error processes. With such gates at a physical error rate of $10^{-3}$, we project that the honeycomb code can reach the teraquop regime with only $600$ physical qubits.","authors":"Craig Gidney, Michael Newman, Austin Fowler, Michael Broughton"},"2108.12477":{"title":"An explicit vector algorithm for high-girth MaxCut","abstract":"We give an approximation algorithm for MaxCut and provide guarantees on the average fraction of edges cut on $d$-regular graphs of girth $\\geq 2k$. For every $d \\geq 3$ and $k \\geq 4$, our approximation guarantees are better than those of all other classical and quantum algorithms known to the authors. Our algorithm constructs an explicit vector solution to the standard semidefinite relaxation of MaxCut and applies hyperplane rounding. It may be viewed as a simplification of the previously best known technique, which approximates Gaussian wave processes on the infinite $d$-regular tree.","authors":"Jessica K. Thompson, Ojas Parekh, Kunal Marwaha"},"2109.00008":{"title":"Unambiguous discrimination of coherent states","abstract":"Coherent states of the quantum electromagnetic field, the quantum description of ideal laser light, are a prime candidate as information carriers for optical communications. A large body of literature exists on quantum-limited parameter estimation and discrimination for coherent states. However, very little is known about practical realizations of receivers for unambiguous state discrimination (USD) of coherent states. Here we fill this gap and establish a theory of unambiguous discrimination of coherent states, with receivers that are allowed to employ: passive multimode linear optics, phase-space displacements, un-excited auxiliary input modes, and on-off photon detection. Our results indicate that these currently-available optical components are near optimal for unambiguous discrimination of multiple coherent states in a constellation.","authors":"Jasminder S. Sidhu, Michael S. Bullock, Saikat Guha, Cosmo Lupo"},"2109.04446":{"title":"Entanglement and superposition are equivalent concepts in any physical theory","abstract":"We prove that any two general probabilistic theories (GPTs) are entangleable, in the sense that their composite exhibits either entangled states or entangled measurements, if and only if they are both non-classical, meaning that neither of the state spaces is a simplex. This establishes the universal equivalence of the (local) superposition principle and the existence of global entanglement, valid in a fully theory-independent way. As an application of our techniques, we show that all non-classical GPTs exhibit a strong form of incompatibility of states and measurements, and use this to construct a version of the BB84 protocol that works in any non-classical GPT.","authors":"Guillaume Aubrun, Ludovico Lami, Carlos Palazuelos, Martin Plávala"},"2109.03687":{"title":"Variational quantum amplitude estimation","abstract":"We propose to perform amplitude estimation with the help of constant-depth quantum circuits that variationally approximate states during amplitude amplification. In the context of Monte Carlo (MC) integration, we numerically show that shallow circuits can accurately approximate many amplitude amplification steps. We combine the variational approach with maximum likelihood amplitude estimation [Y. Suzuki et al., Quantum Inf. Process. 19, 75 (2020)] in variational quantum amplitude estimation (VQAE). VQAE can exhibit a cubic quantum speedup over classical MC sampling if the variational cost is ignored. If this cost is taken into account, VQAE typically has larger computational requirements than classical MC sampling. To reduce the variational cost, we propose adaptive VQAE and numerically show that it can outperform classical MC sampling.","authors":"Kirill Plekhanov, Matthias Rosenkranz, Mattia Fiorentini, Michael Lubasch"},"2109.02600":{"title":"Matrix hypercontractivity, streaming algorithms and LDCs: the large alphabet case","abstract":"In this work, we prove a hypercontractive inequality for matrix-valued functions defined over large alphabets, generalizing a result of Ben-Aroya, Regev, de Wolf (FOCS'08) for the Boolean alphabet. To obtain our result we generalize the powerful $2$-uniform convexity inequality for trace norms of Ball, Carlen, Lieb (Inventiones Mathematicae'94). We give two applications of this hypercontractive inequality. Locally decodable codes (LDC): we present a lower bound for LDCs over large alphabets. An LDC $C:\\mathbb{Z}_r^n\\to \\mathbb{Z}_r^N$ encodes $x\\in\\mathbb{Z}_r^n$ into a codeword $C(x)$ such that one can recover any $x_i$ (with probability at least $1/r+\\varepsilon$) by making a few queries to a corrupted codeword. The main question is the trade-off between $N$ and $n$. By using hypercontractivity, we prove that $N=2^{\\Omega(\\varepsilon^4 n/r^4)}$ for $2$-query (possibly non-linear) LDCs over $\\mathbb{Z}_r$. Previously exponential lower bounds were known for $r=2$ (Kerenidis and de Wolf (JCSS'04)) and for linear codes (Dvir and Shpilka (SICOMP'07)). Streaming algorithms: we present upper and lower bounds for the communication complexity of the Hidden Hypermatching problem when defined over large alphabets, which generalizes the well-known Boolean Hidden Matching problem. We then consider streaming algorithms for approximating the value of Unique Games on a $t$-hyperedge hypergraph: a simple edge-counting argument gives an $r$-approximation with $O(\\log{n})$ space. On the other hand, we use our communication lower bound to show that any streaming algorithm in the adversarial model achieving a $(r-\\varepsilon)$-approximation requires $\\Omega(n^{1-1/t})$ classical or $\\Omega(n^{1-2/t})$ quantum space. In this setting, these results simplify and generalize the seminal work of Kapralov, Khanna and Sudan (SODA'15) and Kapravol and Krachun (STOC'19) when $r=2$.","authors":"Srinivasan Arunachalam, João F. Doriguello"},"2109.10833":{"title":"Bounds on approximating Max $k$XOR with quantum and classical local algorithms","abstract":"We consider the power of local algorithms for approximately solving Max $k$XOR, a generalization of two constraint satisfaction problems previously studied with classical and quantum algorithms (MaxCut and Max E3LIN2). On instances with either random signs or no overlapping clauses and $D+1$ clauses per variable, we calculate the average satisfying fraction of the depth-1 QAOA and compare with a generalization of the local threshold algorithm. Notably, the quantum algorithm outperforms the threshold algorithm for $k &gt; 4$. On the other hand, we highlight potential difficulties for the QAOA to achieve computational quantum advantage on this problem. We first compute a tight upper bound on the maximum satisfying fraction of nearly all large random regular Max $k$XOR instances by numerically calculating the ground state energy density $P(k)$ of a mean-field $k$-spin glass. The upper bound grows with $k$ much faster than the performance of both one-local algorithms. We also identify a new obstruction result for low-depth quantum circuits (including the QAOA) when $k=3$, generalizing a result of Bravyi et al [arXiv:1910.08980] when $k=2$. We conjecture that a similar obstruction exists for all $k$.","authors":"Kunal Marwaha, Stuart Hadfield"},"2011.13661":{"title":"An Almost Constant Lower Bound of the Isoperimetric Coefficient in the KLS Conjecture","abstract":"We prove an almost constant lower bound of the isoperimetric coefficient in the KLS conjecture. The lower bound has the dimension dependency $d^{-o_d(1)}$. When the dimension is large enough, our lower bound is tighter than the previous best bound which has the dimension dependency $d^{-1/4}$. Improving the current best lower bound of the isoperimetric coefficient in the KLS conjecture has many implications, including improvements of the current best bounds in Bourgain's slicing conjecture and in the thin-shell conjecture, better concentration inequalities for Lipschitz functions of log-concave measures and better mixing time bounds for MCMC sampling algorithms on log-concave measures.","authors":"Yuansi Chen"},"2010.05846":{"title":"A Refined Laser Method and Faster Matrix Multiplication","abstract":"The complexity of matrix multiplication is measured in terms of $\\omega$, the smallest real number such that two $n\\times n$ matrices can be multiplied using $O(n^{\\omega+\\epsilon})$ field operations for all $\\epsilon&gt;0$; the best bound until now is $\\omega&lt;2.37287$ [Le Gall'14]. All bounds on $\\omega$ since 1986 have been obtained using the so-called laser method, a way to lower-bound the `value' of a tensor in designing matrix multiplication algorithms. The main result of this paper is a refinement of the laser method that improves the resulting value bound for most sufficiently large tensors. Thus, even before computing any specific values, it is clear that we achieve an improved bound on $\\omega$, and we indeed obtain the best bound on $\\omega$ to date: $$\\omega &lt; 2.37286.$$ The improvement is of the same magnitude as the improvement that [Le Gall'14] obtained over the previous bound [Vassilevska W.'12]. Our improvement to the laser method is quite general, and we believe it will have further applications in arithmetic complexity.","authors":"Josh Alman, Virginia Vassilevska Williams"},"1811.10606":{"title":"Quantum Shockwave Communication","abstract":"We present a scheme to produce shockwaves in quantum fields by means of pretimed emitters. We find that by suitably pre-entangeling the emitters, the shockwave's energy density can be locally modulated and amplified. When the large amplitudes in such a shockwave are used for communication, the channel capacity depends not only on the signal-to-noise ratio but also on the effect that the entanglement of the emitters has on the correlations in the signal and in the quantum noise at the receiver. As a consequence, by choosing the entanglement of the emitters, the flow of information in the shockwave can be modulated and spatially shaped to some extent independently of the flow of energy. We also find that there exists a finite optimal strength of the coupling between the receiver and the quantum field which optimizes the channel capacity by optimizing the tradeoff between sensitivity to the signal and sensitivity to the coupling-induced quantum noise.","authors":"Aida Ahmadzadegan, Eduardo Martin-Martinez, Achim Kempf"},"2005.03791":{"title":"The Power of Adiabatic Quantum Computation with No Sign Problem","abstract":"We show a superpolynomial oracle separation between the power of adiabatic quantum computation with no sign problem and the power of classical computation.","authors":"M. B. Hastings"},"quant-ph/9708016":{"title":"Quantum Algorithms Revisited","abstract":"Quantum computers use the quantum interference of different computational paths to enhance correct outcomes and suppress erroneous outcomes of computations. A common pattern underpinning quantum algorithms can be identified when quantum computation is viewed as multi-particle interference. We use this approach to review (and improve) some of the existing quantum algorithms and to show how they are related to different instances of quantum phase estimation. We provide an explicit algorithm for generating any prescribed interference pattern with an arbitrary precision.","authors":"Richard Cleve, Artur Ekert, Chiara Macchiavello, Michele Mosca"},"2105.01604":{"title":"Orienting Point Clouds with Dipole Propagation","abstract":"Establishing a consistent normal orientation for point clouds is a notoriously difficult problem in geometry processing, requiring attention to both local and global shape characteristics. The normal direction of a point is a function of the local surface neighborhood; yet, point clouds do not disclose the full underlying surface structure. Even assuming known geodesic proximity, calculating a consistent normal orientation requires the global context. In this work, we introduce a novel approach for establishing a globally consistent normal orientation for point clouds. Our solution separates the local and global components into two different sub-problems. In the local phase, we train a neural network to learn a coherent normal direction per patch (i.e., consistently oriented normals within a single patch). In the global phase, we propagate the orientation across all coherent patches using a dipole propagation. Our dipole propagation decides to orient each patch using the electric field defined by all previously orientated patches. This gives rise to a global propagation that is stable, as well as being robust to nearby surfaces, holes, sharp features and noise.","authors":"Gal Metzer, Rana Hanocka, Denis Zorin, Raja Giryes, Daniele Panozzo, Daniel Cohen-Or"},"quant-ph/0304158":{"title":"What is actually teleported?","abstract":"There are no ``unknown quantum states.'' It's a contradiction in terms. Moreover, Alice and Bob are only inanimate objects. They know nothing. What is teleported instantaneously from one system (Alice) to another system (Bob) is the applicability of the preparer's knowledge to the state of a particular qubit in these systems. The operation necessitates dual classical and quantum channels. Other examples of dual transmission, including ``unspeakable information,'' will be presented and discussed. This article also includes a narrative of how I remember that quantum teleportation was conceived.","authors":"Asher Peres"},"1911.12491":{"title":"QKD: Quantization-aware Knowledge Distillation","abstract":"Quantization and Knowledge distillation (KD) methods are widely used to reduce memory and power consumption of deep neural networks (DNNs), especially for resource-constrained edge devices. Although their combination is quite promising to meet these requirements, it may not work as desired. It is mainly because the regularization effect of KD further diminishes the already reduced representation power of a quantized model. To address this short-coming, we propose Quantization-aware Knowledge Distillation (QKD) wherein quantization and KD are care-fully coordinated in three phases. First, Self-studying (SS) phase fine-tunes a quantized low-precision student network without KD to obtain a good initialization. Second, Co-studying (CS) phase tries to train a teacher to make it more quantizaion-friendly and powerful than a fixed teacher. Finally, Tutoring (TU) phase transfers knowledge from the trained teacher to the student. We extensively evaluate our method on ImageNet and CIFAR-10/100 datasets and show an ablation study on networks with both standard and depthwise-separable convolutions. The proposed QKD outperformed existing state-of-the-art methods (e.g., 1.3% improvement on ResNet-18 with W4A4, 2.6% on MobileNetV2 with W4A4). Additionally, QKD could recover the full-precision accuracy at as low as W3A3 quantization on ResNet and W6A6 quantization on MobilenetV2.","authors":"Jangho Kim, Yash Bhalgat, Jinwon Lee, Chirag Patel, Nojun Kwak"},"2111.06500":{"title":"Dynamic Iterative Refinement for Efficient 3D Hand Pose Estimation","abstract":"While hand pose estimation is a critical component of most interactive extended reality and gesture recognition systems, contemporary approaches are not optimized for computational and memory efficiency. In this paper, we propose a tiny deep neural network of which partial layers are recursively exploited for refining its previous estimations. During its iterative refinements, we employ learned gating criteria to decide whether to exit from the weight-sharing loop, allowing per-sample adaptation in our model. Our network is trained to be aware of the uncertainty in its current predictions to efficiently gate at each iteration, estimating variances after each loop for its keypoint estimates. Additionally, we investigate the effectiveness of end-to-end and progressive training protocols for our recursive structure on maximizing the model capacity. With the proposed setting, our method consistently outperforms state-of-the-art 2D/3D hand pose estimation approaches in terms of both accuracy and efficiency for widely used benchmarks.","authors":"John Yang, Yash Bhalgat, Simyung Chang, Fatih Porikli, Nojun Kwak"},"2105.10335":{"title":"Data-driven Weight Initialization with Sylvester Solvers","abstract":"In this work, we propose a data-driven scheme to initialize the parameters of a deep neural network. This is in contrast to traditional approaches which randomly initialize parameters by sampling from transformed standard distributions. Such methods do not use the training data to produce a more informed initialization. Our method uses a sequential layer-wise approach where each layer is initialized using its input activations. The initialization is cast as an optimization problem where we minimize a combination of encoding and decoding losses of the input activations, which is further constrained by a user-defined latent code. The optimization problem is then restructured into the well-known Sylvester equation, which has fast and efficient gradient-free solutions. Our data-driven method achieves a boost in performance compared to random initialization methods, both before start of training and after training is over. We show that our proposed method is especially effective in few-shot and fine-tuning settings. We conclude this paper with analyses on time complexity and the effect of different latent codes on the recognition performance.","authors":"Debasmit Das, Yash Bhalgat, Fatih Porikli"},"2008.02454":{"title":"Structured Convolutions for Efficient Neural Network Design","abstract":"In this work, we tackle model efficiency by exploiting redundancy in the \\textit{implicit structure} of the building blocks of convolutional neural networks. We start our analysis by introducing a general definition of Composite Kernel structures that enable the execution of convolution operations in the form of efficient, scaled, sum-pooling components. As its special case, we propose \\textit{Structured Convolutions} and show that these allow decomposition of the convolution operation into a sum-pooling operation followed by a convolution with significantly lower complexity and fewer weights. We show how this decomposition can be applied to 2D and 3D kernels as well as the fully-connected layers. Furthermore, we present a Structural Regularization loss that promotes neural network layers to leverage on this desired structure in a way that, after training, they can be decomposed with negligible performance loss. By applying our method to a wide range of CNN architectures, we demonstrate \"structured\" versions of the ResNets that are up to 2$\\times$ smaller and a new Structured-MobileNetV2 that is more efficient while staying within an accuracy loss of 1% on ImageNet and CIFAR-10 datasets. We also show similar structured versions of EfficientNet on ImageNet and HRNet architecture for semantic segmentation on the Cityscapes dataset. Our method performs equally well or superior in terms of the complexity reduction in comparison to the existing tensor decomposition and channel pruning methods.","authors":"Yash Bhalgat, Yizhe Zhang, Jamie Lin, Fatih Porikli"},"2004.09576":{"title":"LSQ+: Improving low-bit quantization through learnable offsets and better initialization","abstract":"Unlike ReLU, newer activation functions (like Swish, H-swish, Mish) that are frequently employed in popular efficient architectures can also result in negative activation values, with skewed positive and negative ranges. Typical learnable quantization schemes [PACT, LSQ] assume unsigned quantization for activations and quantize all negative activations to zero which leads to significant loss in performance. Naively using signed quantization to accommodate these negative values requires an extra sign bit which is expensive for low-bit (2-, 3-, 4-bit) quantization. To solve this problem, we propose LSQ+, a natural extension of LSQ, wherein we introduce a general asymmetric quantization scheme with trainable scale and offset parameters that can learn to accommodate the negative activations. Gradient-based learnable quantization schemes also commonly suffer from high instability or variance in the final training performance, hence requiring a great deal of hyper-parameter tuning to reach a satisfactory performance. LSQ+ alleviates this problem by using an MSE-based initialization scheme for the quantization parameters. We show that this initialization leads to significantly lower variance in final performance across multiple training runs. Overall, LSQ+ shows state-of-the-art results for EfficientNet and MixNet and also significantly outperforms LSQ for low-bit quantization of neural nets with Swish activations (e.g.: 1.8% gain with W4A4 quantization and upto 5.6% gain with W2A2 quantization of EfficientNet-B0 on ImageNet dataset). To the best of our knowledge, ours is the first work to quantize such architectures to extremely low bit-widths.","authors":"Yash Bhalgat, Jinwon Lee, Markus Nagel, Tijmen Blankevoort, Nojun Kwak"},"2003.00075":{"title":"Learned Threshold Pruning","abstract":"This paper presents a novel differentiable method for unstructured weight pruning of deep neural networks. Our learned-threshold pruning (LTP) method learns per-layer thresholds via gradient descent, unlike conventional methods where they are set as input. Making thresholds trainable also makes LTP computationally efficient, hence scalable to deeper networks. For example, it takes $30$ epochs for LTP to prune ResNet50 on ImageNet by a factor of $9.1$. This is in contrast to other methods that search for per-layer thresholds via a computationally intensive iterative pruning and fine-tuning process. Additionally, with a novel differentiable $L_0$ regularization, LTP is able to operate effectively on architectures with batch-normalization. This is important since $L_1$ and $L_2$ penalties lose their regularizing effect in networks with batch-normalization. Finally, LTP generates a trail of progressively sparser networks from which the desired pruned network can be picked based on sparsity and performance requirements. These features allow LTP to achieve competitive compression rates on ImageNet networks such as AlexNet ($26.4\\times$ compression with $79.1\\%$ Top-5 accuracy) and ResNet50 ($9.1\\times$ compression with $92.0\\%$ Top-5 accuracy). We also show that LTP effectively prunes modern \\textit{compact} architectures, such as EfficientNet, MobileNetV2 and MixNet.","authors":"Kambiz Azarian, Yash Bhalgat, Jinwon Lee, Tijmen Blankevoort"},"2007.10253":{"title":"Quantum algorithms for escaping from saddle points","abstract":"We initiate the study of quantum algorithms for escaping from saddle points with provable guarantee. Given a function $f\\colon\\mathbb{R}^{n}\\to\\mathbb{R}$, our quantum algorithm outputs an $\\epsilon$-approximate second-order stationary point using $\\tilde{O}(\\log^{2} (n)/\\epsilon^{1.75})$ queries to the quantum evaluation oracle (i.e., the zeroth-order oracle). Compared to the classical state-of-the-art algorithm by Jin et al. with $\\tilde{O}(\\log^{6} (n)/\\epsilon^{1.75})$ queries to the gradient oracle (i.e., the first-order oracle), our quantum algorithm is polynomially better in terms of $\\log n$ and matches its complexity in terms of $1/\\epsilon$. Technically, our main contribution is the idea of replacing the classical perturbations in gradient descent methods by simulating quantum wave equations, which constitutes the improvement in the quantum query complexity with $\\log n$ factors for escaping from saddle points. We also show how to use a quantum gradient computation algorithm due to Jordan to replace the classical gradient queries by quantum evaluation queries with the same complexity. Finally, we also perform numerical experiments that support our theoretical findings.","authors":"Chenyi Zhang, Jiaqi Leng, Tongyang Li"},"1603.08675":{"title":"Quantum Recommendation Systems","abstract":"A recommendation system uses the past purchases or ratings of $n$ products by a group of $m$ users, in order to provide personalized recommendations to individual users. The information is modeled as an $m \\times n$ preference matrix which is assumed to have a good rank-$k$ approximation, for a small constant $k$. In this work, we present a quantum algorithm for recommendation systems that has running time $O(\\text{poly}(k)\\text{polylog}(mn))$. All known classical algorithms for recommendation systems that work through reconstructing an approximation of the preference matrix run in time polynomial in the matrix dimension. Our algorithm provides good recommendations by sampling efficiently from an approximation of the preference matrix, without reconstructing the entire matrix. For this, we design an efficient quantum procedure to project a given vector onto the row space of a given matrix. This is the first algorithm for recommendation systems that runs in time polylogarithmic in the dimensions of the matrix and provides an example of a quantum machine learning algorithm for a real world application.","authors":"Iordanis Kerenidis, Anupam Prakash"},"1307.0401":{"title":"Quantum principal component analysis","abstract":"The usual way to reveal properties of an unknown quantum state, given many copies of a system in that state, is to perform measurements of different observables and to analyze the measurement results statistically. Here we show that the unknown quantum state can play an active role in its own analysis. In particular, given multiple copies of a quantum system with density matrix \\rho, then it is possible to perform the unitary transformation e^{-i\\rho t}. As a result, one can create quantum coherence among different copies of the system to perform quantum principal component analysis, revealing the eigenvectors corresponding to the large eigenvalues of the unknown state in time exponentially faster than any existing algorithm.","authors":"Seth Lloyd, Masoud Mohseni, Patrick Rebentrost"},"1307.0411":{"title":"Quantum algorithms for supervised and unsupervised machine learning","abstract":"Machine-learning tasks frequently involve problems of manipulating and classifying large numbers of vectors in high-dimensional spaces. Classical algorithms for solving such problems typically take time polynomial in the number of vectors and the dimension of the space. Quantum computers are good at manipulating high-dimensional vectors in large tensor product spaces. This paper provides supervised and unsupervised quantum machine learning algorithms for cluster assignment and cluster finding. Quantum machine learning can take time logarithmic in both the number of vectors and their dimension, an exponential speed-up over classical algorithms.","authors":"Seth Lloyd, Masoud Mohseni, Patrick Rebentrost"},"1902.06749":{"title":"A Quantum Interior-Point Predictor-Corrector Algorithm for Linear Programming","abstract":"We introduce a new quantum optimization algorithm for dense Linear Programming problems, which can be seen as the quantization of the Interior Point Predictor-Corrector algorithm \\cite{Predictor-Corrector} using a Quantum Linear System Algorithm \\cite{DenseHHL}. The (worst case) work complexity of our method is, up to polylogarithmic factors, $O(L\\sqrt{n}(n+m)\\overline{||M||_F}\\bar{\\kappa}^2\\epsilon^{-2})$ for $n$ the number of variables in the cost function, $m$ the number of constraints, $\\epsilon^{-1}$ the target precision, $L$ the bit length of the input data, $\\overline{||M||_F}$ an upper bound to the Frobenius norm of the linear systems of equations that appear, $||M||_F$, and $\\bar{\\kappa}$ an upper bound to the condition number $\\kappa$ of those systems of equations. This represents a quantum speed-up in the number $n$ of variables in the cost function with respect to the comparable classical Interior Point algorithms when the initial matrix of the problem $A$ is dense: if we substitute the quantum part of the algorithm by classical algorithms such as Conjugate Gradient Descent, that would mean the whole algorithm has complexity $O(L\\sqrt{n}(n+m)^2\\bar{\\kappa} \\log(\\epsilon^{-1}))$, or with exact methods, at least $O(L\\sqrt{n}(n+m)^{2.373})$. Also, in contrast with any Quantum Linear System Algorithm, the algorithm described in this article outputs a classical description of the solution vector, and the value of the optimal solution.","authors":"P. A. M. Casares, M. A. Martin-Delgado"},"1908.06720":{"title":"Quantum algorithms for Second-Order Cone Programming and Support Vector Machines","abstract":"We present a quantum interior-point method (IPM) for second-order cone programming (SOCP) that runs in time $\\widetilde{O} \\left( n\\sqrt{r} \\frac{\\zeta \\kappa}{\\delta^2} \\log \\left(1/\\epsilon\\right) \\right)$ where $r$ is the rank and $n$ the dimension of the SOCP, $\\delta$ bounds the distance of intermediate solutions from the cone boundary, $\\zeta$ is a parameter upper bounded by $\\sqrt{n}$, and $\\kappa$ is an upper bound on the condition number of matrices arising in the classical IPM for SOCP. The algorithm takes as its input a suitable quantum description of an arbitrary SOCP and outputs a classical description of a $\\delta$-approximate $\\epsilon$-optimal solution of the given problem. Furthermore, we perform numerical simulations to determine the values of the aforementioned parameters when solving the SOCP up to a fixed precision $\\epsilon$. We present experimental evidence that in this case our quantum algorithm exhibits a polynomial speedup over the best classical algorithms for solving general SOCPs that run in time $O(n^{\\omega+0.5})$ (here, $\\omega$ is the matrix multiplication exponent, with a value of roughly $2.37$ in theory, and up to $3$ in practice). For the case of random SVM (support vector machine) instances of size $O(n)$, the quantum algorithm scales as $O(n^k)$, where the exponent $k$ is estimated to be $2.59$ using a least-squares power law. On the same family random instances, the estimated scaling exponent for an external SOCP solver is $3.31$ while that for a state-of-the-art SVM solver is $3.11$.","authors":"Iordanis Kerenidis, Anupam Prakash, Dániel Szilágyi"},"1808.09266":{"title":"A Quantum Interior Point Method for LPs and SDPs","abstract":"We present a quantum interior point method with worst case running time $\\widetilde{O}(\\frac{n^{2.5}}{\\xi^{2}} \\mu \\kappa^3 \\log (1/\\epsilon))$ for SDPs and $\\widetilde{O}(\\frac{n^{1.5}}{\\xi^{2}} \\mu \\kappa^3 \\log (1/\\epsilon))$ for LPs, where the output of our algorithm is a pair of matrices $(S,Y)$ that are $\\epsilon$-optimal $\\xi$-approximate SDP solutions. The factor $\\mu$ is at most $\\sqrt{2}n$ for SDPs and $\\sqrt{2n}$ for LP's, and $\\kappa$ is an upper bound on the condition number of the intermediate solution matrices. For the case where the intermediate matrices for the interior point method are well conditioned, our method provides a polynomial speedup over the best known classical SDP solvers and interior point based LP solvers, which have a worst case running time of $O(n^{6})$ and $O(n^{3.5})$ respectively. Our results build upon recently developed techniques for quantum linear algebra and pave the way for the development of quantum algorithms for a variety of applications in optimization and machine learning.","authors":"Iordanis Kerenidis, Anupam Prakash"},"2011.15094":{"title":"Simulated Quantum Annealing is Efficient on the Spike Hamiltonian","abstract":"In this work we study the convergence of a classical algorithm called Simulated Quantum Annealing (SQA) on the Spike Hamiltonian, a specific toy model Hamiltonian for quantum-mechanical tunneling introduced by [FGG02]. This toy model Hamiltonian encodes a simple bit-symmetric cost function f in the computational basis, and is used to emulate local minima in more complex optimization problems. In previous work [CH16] showed that SQA runs in polynomial time in much of the regime of spikes that QA does, pointing to evidence against an exponential speedup through tunneling. In this paper we extend their analysis to the remaining polynomial regime of energy gaps of the spike Hamiltonian, to show that indeed QA presents no exponential speedup with respect to SQA on this family of toy models.","authors":"Thiago Bergamaschi"},"2202.05186":{"title":"Fair allocation of a multiset of indivisible items","abstract":"We study the problem of allocating a set $M$ of $m$ ${indivisible}$ items among $n$ agents in a fair manner. We consider two well-studied notions of fairness: envy-freeness (EF), and envy-freeness up to any good (EFX). While it is known that complete EF allocations do not always exist, it is not known if complete EFX allocations exist besides a few cases. In this work, we reformulate the problem to allow $M$ to be a multiset. Specifically, we introduce a parameter $t$ for the number of distinct ${types}$ of items, and study allocations of multisets that contain items of these $t$ types. We show the following: 1. For arbitrary $n$, $t$, a complete EF allocation exists when agents have distinct additive valuations, and there are ${enough}$ items of each type. 2. For arbitrary $n$, $m$, $t$, a complete EFX allocation exists when agents have additive valuations with identical ${preferences}$. 3. For arbitrary $n$, $m$, and $t\\le2$, a complete EFX allocation exists when agents have additive valuations. For 2 and 3, our approach is constructive; we give a polynomial-time algorithm to find a complete EFX allocation.","authors":"Pranay Gorantla, Kunal Marwaha, Santhoshini Velusamy"},"2112.00778":{"title":"Quantum advantage in learning from experiments","abstract":"Quantum technology has the potential to revolutionize how we acquire and process experimental data to learn about the physical world. An experimental setup that transduces data from a physical system to a stable quantum memory, and processes that data using a quantum computer, could have significant advantages over conventional experiments in which the physical system is measured and the outcomes are processed using a classical computer. We prove that, in various tasks, quantum machines can learn from exponentially fewer experiments than those required in conventional experiments. The exponential advantage holds in predicting properties of physical systems, performing quantum principal component analysis on noisy states, and learning approximate models of physical dynamics. In some tasks, the quantum processing needed to achieve the exponential advantage can be modest; for example, one can simultaneously learn about many noncommuting observables by processing only two copies of the system. Conducting experiments with up to 40 superconducting qubits and 1300 quantum gates, we demonstrate that a substantial quantum advantage can be realized using today's relatively noisy quantum processors. Our results highlight how quantum technology can enable powerful new strategies to learn about nature.","authors":"Hsin-Yuan Huang, Michael Broughton, Jordan Cotler, Sitan Chen, Jerry Li, Masoud Mohseni, Hartmut Neven, Ryan Babbush, Richard Kueng, John Preskill, Jarrod R. McClean"},"2108.05803":{"title":"Averaged circuit eigenvalue sampling","abstract":"We introduce ACES, a method for scalable noise metrology of quantum circuits that stands for Averaged Circuit Eigenvalue Sampling. It simultaneously estimates the individual error rates of all the gates in collections of quantum circuits, and can even account for space and time correlations between these gates. ACES strictly generalizes randomized benchmarking (RB), interleaved RB, simultaneous RB, and several other related techniques. However, ACES provides much more information and provably works under strictly weaker assumptions than these techniques. Finally, ACES is extremely scalable: we demonstrate with numerical simulations that it simultaneously and precisely estimates all the Pauli error rates on every gate and measurement in a 100 qubit quantum device using fewer than 20 relatively shallow Clifford circuits and an experimentally feasible number of samples. By learning the detailed gate errors for large quantum devices, ACES opens new possibilities for error mitigation, bespoke quantum error correcting codes and decoders, customized compilers, and more.","authors":"Steven T. Flammia"},"2109.14599":{"title":"Bounds on stabilizer measurement circuits and obstructions to local implementations of quantum LDPC codes","abstract":"In this work we establish lower bounds on the size of Clifford circuits that measure a family of commuting Pauli operators. Our bounds depend on the interplay between a pair of graphs: the Tanner graph of the set of measured Pauli operators, and the connectivity graph which represents the qubit connections required to implement the circuit. For local-expander quantum codes, which are promising for low-overhead quantum error correction, we prove that any syndrome extraction circuit implemented with local Clifford gates in a 2D square patch of $N$ qubits has depth at least $\\Omega(n/\\sqrt{N})$ where $n$ is the code length. Then, we propose two families of quantum circuits saturating this bound. First, we construct 2D local syndrome extraction circuits for quantum LDPC codes with bounded depth using only $O(n^2)$ ancilla qubits. Second, we design a family of 2D local syndrome extraction circuits for hypergraph product codes using $O(n)$ ancilla qubits with depth $O(\\sqrt{n})$. Finally, we use circuit noise simulations to compare the performance of a family of hypergraph product codes using this last family of 2D syndrome extraction circuits with a syndrome extraction circuit implemented with fully connected qubits. While there is a threshold of about $10^{-3}$ for a fully connected implementation, we observe no threshold for the 2D local implementation despite simulating error rates of as low as $10^{-6}$. This suggests that quantum LDPC codes are impractical with 2D local quantum hardware. We believe that our proof technique is of independent interest and could find other applications. Our bounds on circuit sizes are derived from a lower bound on the amount of correlations between two subsets of qubits of the circuit and an upper bound on the amount of correlations introduced by each circuit gate, which together provide a lower bound on the circuit size.","authors":"Nicolas Delfosse, Michael E. Beverland, Maxime A. Tremblay"},"2109.14609":{"title":"Constant-overhead quantum error correction with thin planar connectivity","abstract":"Quantum LDPC codes may provide a path to build low-overhead fault-tolerant quantum computers. However, as general LDPC codes lack geometric constraints, na\\\"ive layouts couple many distant qubits with crossing connections which could be hard to build in hardware and could result in performance-degrading crosstalk. We propose a 2D layout for quantum LDPC codes by decomposing their Tanner graphs into a small number of planar layers. Each layer contains long-range connections which do not cross. For any CSS code with a degree-$\\delta$ Tanner graph, we design stabilizer measurement circuits with depth at most $(2\\delta +2)$ using at most $\\lceil \\delta/2 \\rceil$ layers. We observe a circuit-noise threshold of 0.28\\% for a positive-rate code family using 49 physical qubits per logical qubit. For a physical error rate of $10^{-4}$, this family reaches a logical error rate of $10^{-15}$ using fourteen times fewer physical qubits than the surface code.","authors":"Maxime A. Tremblay, Nicolas Delfosse, Michael E. Beverland"},"2111.02296":{"title":"On polynomially many queries to NP or QMA oracles","abstract":"We study the complexity of problems solvable in deterministic polynomial time with access to an NP or Quantum Merlin-Arthur (QMA)-oracle, such as $P^{NP}$ and $P^{QMA}$, respectively. The former allows one to classify problems more finely than the Polynomial-Time Hierarchy (PH), whereas the latter characterizes physically motivated problems such as Approximate Simulation (APX-SIM) [Ambainis, CCC 2014]. In this area, a central role has been played by the classes $P^{NP[\\log]}$ and $P^{QMA[\\log]}$, defined identically to $P^{NP}$ and $P^{QMA}$, except that only logarithmically many oracle queries are allowed. Here, [Gottlob, FOCS 1993] showed that if the adaptive queries made by a $P^{NP}$ machine have a \"query graph\" which is a tree, then this computation can be simulated in $P^{NP[\\log]}$. In this work, we first show that for any verification class $C\\in\\{NP,MA,QCMA,QMA,QMA(2),NEXP,QMA_{\\exp}\\}$, any $P^C$ machine with a query graph of \"separator number\" $s$ can be simulated using deterministic time $\\exp(s\\log n)$ and $s\\log n$ queries to a $C$-oracle. When $s\\in O(1)$ (which includes the case of $O(1)$-treewidth, and thus also of trees), this gives an upper bound of $P^{C[\\log]}$, and when $s\\in O(\\log^k(n))$, this yields bound $QP^{C[\\log^{k+1}]}$ (QP meaning quasi-polynomial time). We next show how to combine Gottlob's \"admissible-weighting function\" framework with the \"flag-qubit\" framework of [Watson, Bausch, Gharibian, 2020], obtaining a unified approach for embedding $P^C$ computations directly into APX-SIM instances in a black-box fashion. Finally, we formalize a simple no-go statement about polynomials (c.f. [Krentel, STOC 1986]): Given a multi-linear polynomial $p$ specified via an arithmetic circuit, if one can \"weakly compress\" $p$ so that its optimal value requires $m$ bits to represent, then $P^{NP}$ can be decided with only $m$ queries to an NP-oracle.","authors":"Sevag Gharibian, Dorian Rudolph"},"2203.02968":{"title":"Improved Quantum Query Upper Bounds Based on Classical Decision Trees","abstract":"Given a classical query algorithm as a decision tree, when does there exist a quantum query algorithm with a speed-up over the classical one? We provide a general construction based on the structure of the underlying decision tree, and prove that this can give us an up-to-quadratic quantum speed-up. In particular, we obtain a bounded-error quantum query algorithm of cost $O(\\sqrt{s})$ to compute a Boolean function (more generally, a relation) that can be computed by a classical (even randomized) decision tree of size $s$. Lin and Lin [ToC'16] and Beigi and Taghavi [Quantum'20] showed results of a similar flavor, and gave upper bounds in terms of a quantity which we call the \"guessing complexity\" of a decision tree. We identify that the guessing complexity of a decision tree equals its rank, a notion introduced by Ehrenfeucht and Haussler [Inf. Comp.'89] in the context of learning theory. This answers a question posed by Lin and Lin, who asked whether the guessing complexity of a decision tree is related to any complexity-theoretic measure. We also show a polynomial separation between rank and randomized rank for the complete binary AND-OR tree. Beigi and Taghavi constructed span programs and dual adversary solutions for Boolean functions given classical decision trees computing them and an assignment of non-negative weights to its edges. We explore the effect of changing these weights on the resulting span program complexity and objective value of the dual adversary bound, and capture the best possible weighting scheme by an optimization program. We exhibit a solution to this program and argue its optimality from first principles. We also exhibit decision trees for which our bounds are asymptotically stronger than those of Lin and Lin, and Beigi and Taghavi. This answers a question of Beigi and Taghavi, who asked whether different weighting schemes could yield better upper bounds.","authors":"Arjan Cornelissen, Nikhil S. Mande, Subhasree Patro"},"2204.12303":{"title":"On converses to the polynomial method","abstract":"A surprising 'converse to the polynomial method' of Aaronson et al. (CCC'16) shows that any bounded quadratic polynomial can be computed exactly in expectation by a 1-query algorithm up to a universal multiplicative factor related to the famous Grothendieck constant. A natural question posed there asks if bounded quartic polynomials can be approximated by $2$-query quantum algorithms. Arunachalam, Palazuelos and the first author showed that there is no direct analogue of the result of Aaronson et al. in this case. We improve on this result in the following ways: First, we point out and fix a small error in the construction that has to do with a translation from cubic to quartic polynomials. Second, we give a completely explicit example based on techniques from additive combinatorics. Third, we show that the result still holds when we allow for a small additive error. For this, we apply an SDP characterization of Gribling and Laurent (QIP'19) for the completely-bounded approximate degree.","authors":"Jop Briët, Francisco Escudero Gutiérrez"},"2105.12067":{"title":"Holographic duality between local Hamiltonians from random tensor networks","abstract":"The AdS/CFT correspondence realises the holographic principle where information in the bulk of a space is encoded at its border. We are yet a long way from a full mathematical construction of AdS/CFT, but toy models in the form of holographic quantum error correcting codes (HQECC) have replicated some interesting features of the correspondence. In this work we construct new HQECCs built from random stabilizer tensors that describe a duality between models encompassing local Hamiltonians whilst exactly obeying the Ryu-Takayanagi entropy formula for all boundary regions. We also obtain complementary recovery of local bulk operators for any boundary bipartition. Existing HQECCs have been shown to exhibit these properties individually, whereas our mathematically rigorous toy models capture these features of AdS/CFT simultaneously, advancing further towards a complete construction of holographic duality.","authors":"Harriet Apel, Tamara Kohler, Toby Cubitt"},"2110.15466":{"title":"On the complexity of quantum partition functions","abstract":"The partition function and free energy of a quantum many-body system determine its physical properties in thermal equilibrium. Here we study the computational complexity of approximating these quantities for $n$-qubit local Hamiltonians. First, we report a classical algorithm with $\\mathrm{poly}(n)$ runtime which approximates the free energy of a given $2$-local Hamiltonian provided that it satisfies a certain denseness condition. Our algorithm combines the variational characterization of the free energy and convex relaxation methods. It contributes to a body of work on efficient approximation algorithms for dense instances of optimization problems which are hard in the general case, and can be viewed as simultaneously extending existing algorithms for (a) the ground energy of dense $2$-local Hamiltonians, and (b) the free energy of dense classical Ising models. Secondly, we establish polynomial-time equivalence between the problem of approximating the free energy of local Hamiltonians and three other natural quantum approximate counting problems, including the problem of approximating the number of witness states accepted by a QMA verifier. These results suggest that simulation of quantum many-body systems in thermal equilibrium may precisely capture the complexity of a broad family of computational problems that has yet to be defined or characterized in terms of known complexity classes. Finally, we summarize state-of-the-art classical and quantum algorithms for approximating the free energy and show how to improve their runtime and memory footprint.","authors":"Sergey Bravyi, Anirban Chowdhury, David Gosset, Pawel Wocjan"},"2111.07992":{"title":"Query and Depth Upper Bounds for Quantum Unitaries via Grover Search","abstract":"We prove that any $n$-qubit unitary can be implemented (i) approximately in time $\\tilde O\\big(2^{n/2}\\big)$ with query access to an appropriate classical oracle, and also (ii) exactly by a circuit of depth $\\tilde O\\big(2^{n/2}\\big)$ with one- and two-qubit gates and $2^{O(n)}$ ancillae. The proofs of (i) and (ii) involve similar reductions to Grover search. The proof of (ii) also involves a linear-depth construction of arbitrary quantum states using one- and two-qubit gates (in fact, this can be improved to constant depth with the addition of fanout and generalized Toffoli gates) which may be of independent interest. We also prove a matching $\\Omega\\big(2^{n/2}\\big)$ lower bound for (i) and (ii) for a certain class of implementations.","authors":"Gregory Rosenthal"},"2111.03103":{"title":"Time-dependent Hamiltonian Simulation of Highly Oscillatory Dynamics and Superconvergence for Schrödinger Equation","abstract":"We propose a simple quantum algorithm for simulating highly oscillatory quantum dynamics, which does not require complicated quantum control logic for handling time-ordering operators. To our knowledge, this is the first quantum algorithm that is both insensitive to the rapid changes of the time-dependent Hamiltonian and exhibits commutator scaling. Our method can be used for efficient Hamiltonian simulation in the interaction picture. In particular, we demonstrate that for the simulation of the Schr\\\"odinger equation, our method exhibits superconvergence and achieves a surprising second order convergence rate, of which the proof rests on a careful application of pseudo-differential calculus. Numerical results verify the effectiveness and the superconvergence property of our method.","authors":"Dong An, Di Fang, Lin Lin"},"2202.08349":{"title":"Approximating Output Probabilities of Shallow Quantum Circuits which are Geometrically-local in any Fixed Dimension","abstract":"We present a classical algorithm that, for any $D$-dimensional geometrically-local, quantum circuit $C$ of polylogarithmic-depth, and any bit string $x \\in {0,1}^n$, can compute the quantity $|&lt;x|C|0^{\\otimes n}&gt;|^2$ to within any inverse-polynomial additive error in quasi-polynomial time, for any fixed dimension $D$. This is an extension of the result [CC21], which originally proved this result for $D = 3$. To see why this is interesting, note that, while the $D = 1$ case of this result follows from standard use of Matrix Product States, known for decades, the $D = 2$ case required novel and interesting techniques introduced in [BGM19]. Extending to the case $D = 3$ was even more laborious and required further new techniques introduced in [CC21]. Our work here shows that, while handling each new dimension has historically required a new insight, and fixed algorithmic primitive, based on known techniques for $D \\leq 3$, we can now handle any fixed dimension $D &gt; 3$. Our algorithm uses the Divide-and-Conquer framework of [CC21] to approximate the desired quantity via several instantiations of the same problem type, each involving $D$-dimensional circuits on about half the number of qubits as the original. This division step is then applied recursively, until the width of the recursively decomposed circuits in the $D^{th}$ dimension is so small that they can effectively be regarded as $(D-1)$-dimensional problems by absorbing the small width in the $D^{th}$ dimension into the qudit structure at the cost of a moderate increase in runtime. The main technical challenge lies in ensuring that the more involved portions of the recursive circuit decomposition and error analysis from [CC21] still hold in higher dimensions, which requires small modifications to the analysis in some places.","authors":"Suchetan Dontha, Shi Jie Samuel Tan, Stephen Smith, Sangheon Choi, Matthew Coudron"}}